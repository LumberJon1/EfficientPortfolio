{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709e3394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SPY</th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAAP</th>\n",
       "      <th>AABB</th>\n",
       "      <th>AAC</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAMC</th>\n",
       "      <th>AAME</th>\n",
       "      <th>...</th>\n",
       "      <th>ZSTN</th>\n",
       "      <th>ZTR</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>ZULU</th>\n",
       "      <th>ZUMZ</th>\n",
       "      <th>ZVLO</th>\n",
       "      <th>ZVTK</th>\n",
       "      <th>ZWBC</th>\n",
       "      <th>ZYNE</th>\n",
       "      <th>ZYXI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01/03/2000</th>\n",
       "      <td>0</td>\n",
       "      <td>94.262558</td>\n",
       "      <td>43.76</td>\n",
       "      <td>70.69</td>\n",
       "      <td>24.50</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.87</td>\n",
       "      <td>18.19</td>\n",
       "      <td>9.26</td>\n",
       "      <td>2.09</td>\n",
       "      <td>...</td>\n",
       "      <td>7.52</td>\n",
       "      <td>2.46</td>\n",
       "      <td>29.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12.44</td>\n",
       "      <td>26.75</td>\n",
       "      <td>3750000.0</td>\n",
       "      <td>12.75</td>\n",
       "      <td>16.25</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/04/2000</th>\n",
       "      <td>1</td>\n",
       "      <td>90.576347</td>\n",
       "      <td>40.42</td>\n",
       "      <td>71.02</td>\n",
       "      <td>25.00</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.96</td>\n",
       "      <td>19.33</td>\n",
       "      <td>8.65</td>\n",
       "      <td>2.15</td>\n",
       "      <td>...</td>\n",
       "      <td>7.20</td>\n",
       "      <td>2.48</td>\n",
       "      <td>29.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12.26</td>\n",
       "      <td>25.00</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>12.75</td>\n",
       "      <td>19.32</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/05/2000</th>\n",
       "      <td>2</td>\n",
       "      <td>90.738327</td>\n",
       "      <td>37.91</td>\n",
       "      <td>75.11</td>\n",
       "      <td>25.26</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.78</td>\n",
       "      <td>19.05</td>\n",
       "      <td>8.26</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2.49</td>\n",
       "      <td>29.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12.05</td>\n",
       "      <td>27.50</td>\n",
       "      <td>7500000.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>24.54</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/06/2000</th>\n",
       "      <td>3</td>\n",
       "      <td>89.280045</td>\n",
       "      <td>36.46</td>\n",
       "      <td>74.13</td>\n",
       "      <td>25.02</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.83</td>\n",
       "      <td>19.81</td>\n",
       "      <td>8.39</td>\n",
       "      <td>2.09</td>\n",
       "      <td>...</td>\n",
       "      <td>7.55</td>\n",
       "      <td>2.51</td>\n",
       "      <td>29.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12.12</td>\n",
       "      <td>25.50</td>\n",
       "      <td>4450000.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>35.14</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/07/2000</th>\n",
       "      <td>4</td>\n",
       "      <td>94.465111</td>\n",
       "      <td>39.50</td>\n",
       "      <td>73.91</td>\n",
       "      <td>24.62</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.90</td>\n",
       "      <td>20.27</td>\n",
       "      <td>8.96</td>\n",
       "      <td>2.15</td>\n",
       "      <td>...</td>\n",
       "      <td>7.31</td>\n",
       "      <td>2.56</td>\n",
       "      <td>29.98</td>\n",
       "      <td>0.05</td>\n",
       "      <td>11.75</td>\n",
       "      <td>27.34</td>\n",
       "      <td>2750000.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>29.73</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6078 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0        SPY      A     AA   AAAP   AABB   AAC    AAL  \\\n",
       "Date                                                                         \n",
       "01/03/2000           0  94.262558  43.76  70.69  24.50  77.49  9.87  18.19   \n",
       "01/04/2000           1  90.576347  40.42  71.02  25.00  77.49  9.96  19.33   \n",
       "01/05/2000           2  90.738327  37.91  75.11  25.26  77.49  9.78  19.05   \n",
       "01/06/2000           3  89.280045  36.46  74.13  25.02  77.49  9.83  19.81   \n",
       "01/07/2000           4  94.465111  39.50  73.91  24.62  77.49  9.90  20.27   \n",
       "\n",
       "            AAMC  AAME  ...  ZSTN   ZTR    ZTS  ZULU   ZUMZ   ZVLO  \\\n",
       "Date                    ...                                          \n",
       "01/03/2000  9.26  2.09  ...  7.52  2.46  29.05  0.06  12.44  26.75   \n",
       "01/04/2000  8.65  2.15  ...  7.20  2.48  29.06  0.06  12.26  25.00   \n",
       "01/05/2000  8.26  2.20  ...  7.50  2.49  29.08  0.05  12.05  27.50   \n",
       "01/06/2000  8.39  2.09  ...  7.55  2.51  29.07  0.05  12.12  25.50   \n",
       "01/07/2000  8.96  2.15  ...  7.31  2.56  29.98  0.05  11.75  27.34   \n",
       "\n",
       "                  ZVTK   ZWBC   ZYNE  ZYXI  \n",
       "Date                                        \n",
       "01/03/2000   3750000.0  12.75  16.25  1.28  \n",
       "01/04/2000  10000000.0  12.75  19.32  1.31  \n",
       "01/05/2000   7500000.0  30.00  24.54  1.32  \n",
       "01/06/2000   4450000.0  25.00  35.14  1.31  \n",
       "01/07/2000   2750000.0  16.00  29.73  1.29  \n",
       "\n",
       "[5 rows x 6078 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "project_dir = \"c:\\\\Users\\\\Jonathan\\\\Desktop\\\\Bootcamp\\\\Python\\\\EfficientPortfolio\\\\\"\n",
    "\n",
    "df = pd.read_csv(\"all_history.csv\")\n",
    "df = df.set_index(\"Date\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_history(ticker, interval=\"1d\", period=\"1y\",\n",
    "#                 start_date=\"2000-01-01\", end_date=\"2023-11-14\"\n",
    "#                 ):\n",
    "#     # Interval can be \"1d\", \"5d\", \"1wk\", \"1mo\", or \"3mo\"\n",
    "#     # start and end are given in str, dt, or int: \"YYYY-MM-DD\", datetime, or epoch respectively.\n",
    "#     # Alternatively, we can use a period argument in place of start and end dates.\n",
    "#     # period can equal \"3mo\", \"6mo\", \"1y\", \"2y\", \"5y\", \"10y\", \"ytd\", or \"max\".\n",
    "    \n",
    "#     # TODO: Validate based on duration and/or interval to prevent out-of-bounds dates\n",
    "    \n",
    "#     stock = yf.Ticker(ticker)\n",
    "#     history = stock.history(interval=interval, period=period, start=start_date, end=end_date)\n",
    "    \n",
    "#     # if len(history) == 0:\n",
    "#     #     print(\"No history available.\")\n",
    "#     #     return\n",
    "    \n",
    "#     # Reset index to make Date accessible\n",
    "#     history = history.reset_index()\n",
    "#     # print(history)\n",
    "    \n",
    "#     # Return the dataframe\n",
    "#     return history\n",
    "\n",
    "# benchmark_history_df = get_history(\"SPY\")\n",
    "# benchmark_history_df = benchmark_history_df[[\"Date\", \"Close\"]]\n",
    "# benchmark_history_df['Date'] = benchmark_history_df['Date'].dt.strftime('%m/%d/%Y')\n",
    "# benchmark_history_df.set_index(\"Date\", inplace=True)\n",
    "# benchmark_history_df.rename(columns={\"Close\": \"SPY\"}, inplace=True)\n",
    "# print(benchmark_history_df.columns)\n",
    "\n",
    "# large_df = pd.read_csv(os.path.join(project_dir, \"all_history.csv\"))\n",
    "# # print(large_df.columns[-1])\n",
    "\n",
    "# new_df = pd.merge(benchmark_history_df, large_df, on=\"Date\", how=\"outer\")\n",
    "# # print(new_df.columns[-1])\n",
    "# new_df.head(10)\n",
    "\n",
    "# print(new_df[\"AA\"].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = new_df.reset_index()\n",
    "# new_df.loc[new_df.index[-1], \"SPY\"]\n",
    "# new_df.loc[new_df.index[-1], \"Date\"]\n",
    "# new_df.loc[:]\n",
    "# new_df.to_csv(path_or_buf=os.path.join(project_dir, \"all_history.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SPY</th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAAP</th>\n",
       "      <th>AABB</th>\n",
       "      <th>AAC</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAMC</th>\n",
       "      <th>...</th>\n",
       "      <th>ZSTN</th>\n",
       "      <th>ZTR</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>ZULU</th>\n",
       "      <th>ZUMZ</th>\n",
       "      <th>ZVLO</th>\n",
       "      <th>ZVTK</th>\n",
       "      <th>ZWBC</th>\n",
       "      <th>ZYNE</th>\n",
       "      <th>ZYXI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/03/2000</td>\n",
       "      <td>0</td>\n",
       "      <td>94.262558</td>\n",
       "      <td>43.76</td>\n",
       "      <td>70.69</td>\n",
       "      <td>24.50</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.87</td>\n",
       "      <td>18.19</td>\n",
       "      <td>9.26</td>\n",
       "      <td>...</td>\n",
       "      <td>7.52</td>\n",
       "      <td>2.46</td>\n",
       "      <td>29.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12.44</td>\n",
       "      <td>26.75</td>\n",
       "      <td>3750000.0</td>\n",
       "      <td>12.75</td>\n",
       "      <td>16.25</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/04/2000</td>\n",
       "      <td>1</td>\n",
       "      <td>90.576347</td>\n",
       "      <td>40.42</td>\n",
       "      <td>71.02</td>\n",
       "      <td>25.00</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.96</td>\n",
       "      <td>19.33</td>\n",
       "      <td>8.65</td>\n",
       "      <td>...</td>\n",
       "      <td>7.20</td>\n",
       "      <td>2.48</td>\n",
       "      <td>29.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12.26</td>\n",
       "      <td>25.00</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>12.75</td>\n",
       "      <td>19.32</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/05/2000</td>\n",
       "      <td>2</td>\n",
       "      <td>90.738327</td>\n",
       "      <td>37.91</td>\n",
       "      <td>75.11</td>\n",
       "      <td>25.26</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.78</td>\n",
       "      <td>19.05</td>\n",
       "      <td>8.26</td>\n",
       "      <td>...</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2.49</td>\n",
       "      <td>29.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12.05</td>\n",
       "      <td>27.50</td>\n",
       "      <td>7500000.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>24.54</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/06/2000</td>\n",
       "      <td>3</td>\n",
       "      <td>89.280045</td>\n",
       "      <td>36.46</td>\n",
       "      <td>74.13</td>\n",
       "      <td>25.02</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.83</td>\n",
       "      <td>19.81</td>\n",
       "      <td>8.39</td>\n",
       "      <td>...</td>\n",
       "      <td>7.55</td>\n",
       "      <td>2.51</td>\n",
       "      <td>29.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12.12</td>\n",
       "      <td>25.50</td>\n",
       "      <td>4450000.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>35.14</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/07/2000</td>\n",
       "      <td>4</td>\n",
       "      <td>94.465111</td>\n",
       "      <td>39.50</td>\n",
       "      <td>73.91</td>\n",
       "      <td>24.62</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.90</td>\n",
       "      <td>20.27</td>\n",
       "      <td>8.96</td>\n",
       "      <td>...</td>\n",
       "      <td>7.31</td>\n",
       "      <td>2.56</td>\n",
       "      <td>29.98</td>\n",
       "      <td>0.05</td>\n",
       "      <td>11.75</td>\n",
       "      <td>27.34</td>\n",
       "      <td>2750000.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>29.73</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6079 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Unnamed: 0        SPY      A     AA   AAAP   AABB   AAC    AAL  \\\n",
       "0  01/03/2000           0  94.262558  43.76  70.69  24.50  77.49  9.87  18.19   \n",
       "1  01/04/2000           1  90.576347  40.42  71.02  25.00  77.49  9.96  19.33   \n",
       "2  01/05/2000           2  90.738327  37.91  75.11  25.26  77.49  9.78  19.05   \n",
       "3  01/06/2000           3  89.280045  36.46  74.13  25.02  77.49  9.83  19.81   \n",
       "4  01/07/2000           4  94.465111  39.50  73.91  24.62  77.49  9.90  20.27   \n",
       "\n",
       "   AAMC  ...  ZSTN   ZTR    ZTS  ZULU   ZUMZ   ZVLO        ZVTK   ZWBC   ZYNE  \\\n",
       "0  9.26  ...  7.52  2.46  29.05  0.06  12.44  26.75   3750000.0  12.75  16.25   \n",
       "1  8.65  ...  7.20  2.48  29.06  0.06  12.26  25.00  10000000.0  12.75  19.32   \n",
       "2  8.26  ...  7.50  2.49  29.08  0.05  12.05  27.50   7500000.0  30.00  24.54   \n",
       "3  8.39  ...  7.55  2.51  29.07  0.05  12.12  25.50   4450000.0  25.00  35.14   \n",
       "4  8.96  ...  7.31  2.56  29.98  0.05  11.75  27.34   2750000.0  16.00  29.73   \n",
       "\n",
       "   ZYXI  \n",
       "0  1.28  \n",
       "1  1.31  \n",
       "2  1.32  \n",
       "3  1.31  \n",
       "4  1.29  \n",
       "\n",
       "[5 rows x 6079 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_df = df.reset_index()\n",
    "# date_value = reset_df.loc[reset_df[\"Date\"] == \"01/05/2000\", \"Date\"].index[0]\n",
    "reset_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5256\n"
     ]
    }
   ],
   "source": [
    "start_date = \"11/21/2020\"\n",
    "start_date_index = reset_df.loc[reset_df[\"Date\"] == \"11/20/2020\", \"Date\"].index[0]\n",
    "print(start_date_index)\n",
    "# print(\"Start date: \"+)\n",
    "# print(\"Set start date index for portfolio instance to: \"+str(start_date_index))\n",
    "# print(df.loc[start_date_index, \"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     94.262558\n",
       "1     90.576347\n",
       "2     90.738327\n",
       "3     89.280045\n",
       "4     94.465111\n",
       "5     94.789192\n",
       "6     93.654945\n",
       "7     92.723259\n",
       "8     93.979027\n",
       "9     95.255013\n",
       "10    94.505608\n",
       "11    95.275246\n",
       "12    93.816948\n",
       "13    93.614433\n",
       "14    90.961166\n",
       "15    91.994102\n",
       "16    91.264954\n",
       "17    90.900391\n",
       "18    88.064796\n",
       "19    90.454788\n",
       "20    91.345970\n",
       "21    91.427025\n",
       "22    92.804337\n",
       "23    92.419464\n",
       "24    92.277679\n",
       "25    93.533447\n",
       "26    91.568741\n",
       "27    91.751045\n",
       "28    89.887665\n",
       "29    90.414268\n",
       "Name: SPY, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_df[\"SPY\"].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fb02867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will store the period, start date, and portfolios in a class file.  We can then have\n",
    "# an array of Portfolios to compare.\n",
    "\n",
    "class Portfolio:\n",
    "    # instance variables/attributes...\n",
    "    size = 10 # The initial size or num_stocks in the portfolio\n",
    "    n_periods = 10 # The number of trading days the portfolio analysis takes place over\n",
    "    start_date_index = 0\n",
    "    \n",
    "    weights = pd.DataFrame({}) # Weights that will be assigned to each of the assets in the portfolio\n",
    "    \n",
    "    stdev = 0\n",
    "    hpr = 0\n",
    "    hpr_annualized = 0\n",
    "    risk_adj_return = 0\n",
    "    alpha = 0\n",
    "    \n",
    "    history_df = pd.DataFrame({})\n",
    "    analysis_df = pd.DataFrame({})\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, size, n_periods, start_date=\"Random\"):\n",
    "        \n",
    "        self.size = size\n",
    "        self.n_periods = n_periods\n",
    "        \n",
    "        # If a number is given for start_date, set start_date_index to that number\n",
    "        if (type(start_date) == int):\n",
    "            # print(\"Chose an int index for start_date_index\")\n",
    "            self.start_date_index = start_date\n",
    "        \n",
    "        # Else if a date is given, find that index\n",
    "        elif (start_date != \"Random\"):\n",
    "            # TODO: Validate format and catch errors or re-format properly\n",
    "            start_date_index = reset_df.loc[reset_df[\"Date\"] == start_date, \"Date\"].index[0]\n",
    "            # print(\"Start date: \"+)\n",
    "            print(\"Set start date index for portfolio instance to: \"+str(start_date_index))\n",
    "            print(reset_df.loc[start_date_index, \"Date\"])\n",
    "            # print(\"Found index within df at \"+str(start_date))\n",
    "            \n",
    "            self.start_date_index = start_date_index\n",
    "            \n",
    "        \n",
    "        # Else (or if no args are given) - randomize\n",
    "        else:\n",
    "            self.randomize_start()\n",
    "        \n",
    "        \n",
    "        # Generate history_df\n",
    "        self.create_portfolio()\n",
    "        \n",
    "        # Assign weights\n",
    "        self.assignWeights()\n",
    "        \n",
    "        print(\"Initialized new Portfolio instance\")\n",
    "        \n",
    "    \n",
    "    # Methods...\n",
    "    \n",
    "    # NOTE: Both randomize_ricker and randomize_start need access to the massive CSV file and currently take a pre-made df\n",
    "    # not as an argument, but as a variable inside them.  This will need to be changed in whatever file I move this to.\n",
    "    def randomize_ticker(self):\n",
    "        ticker_index = random.randint(0, len(df.columns) - 1)\n",
    "        sub_df = df.iloc[:, ticker_index]\n",
    "        return sub_df.name.upper()\n",
    "    \n",
    "\n",
    "    def randomize_start(self):\n",
    "        \"\"\"Takes a length parameter that will be added to a random start date and represent the period analyzed\"\"\"\n",
    "        # NOTE: This uses the length of df, which does not exist in the class.  Might be better to define the read_csv here in the class file.\n",
    "        # Perhaps pass it as an argument in randomize_start and have that param point to the read_csv\n",
    "        rand_start = random.randint(0, (len(df) - self.n_periods))\n",
    "        \n",
    "        self.start_date_index = rand_start\n",
    "        return self.start_date_index\n",
    "    \n",
    "    \n",
    "    def create_portfolio(self):\n",
    "    #   df to hold the data from each ticker\n",
    "        prices_df = pd.DataFrame({})\n",
    "\n",
    "        start_index = self.start_date_index\n",
    "        \n",
    "        i = 0\n",
    "        while i < self.size:\n",
    "    #       Run the randomizer and trim values\n",
    "            ticker = self.randomize_ticker()\n",
    "            ticker_index = df.columns.get_loc(ticker)\n",
    "            ticker_df = df.iloc[start_index : start_index + self.n_periods, [ticker_index]]\n",
    "\n",
    "    #       Clean null values and randomize again if necessary\n",
    "            ticker_df = ticker_df.dropna()\n",
    "            if (len(ticker_df) < self.n_periods):\n",
    "                # Break and decrement i if there are null values in the date range\n",
    "                # print(\"\\nSeries contains null values.  Choosing a different ticker...\")\n",
    "                i -= 1\n",
    "\n",
    "            else:\n",
    "                # Add the data as intended.\n",
    "                if prices_df.empty:\n",
    "                    prices_df = ticker_df\n",
    "                else:\n",
    "                    prices_df = pd.concat([prices_df, ticker_df], axis=1)\n",
    "    #                   prices_df = prices_df.merge(prices_df, ticker_df)\n",
    "    #       \n",
    "            i += 1\n",
    "        \n",
    "        # Load with the percentage change columns\n",
    "        for item in prices_df.columns:\n",
    "    #       First, load with values\n",
    "            prices_df[str(item)+\" % chg\"] = prices_df[item].pct_change()\n",
    "        \n",
    "        # print(\"\\n\\nFinal prices_df: \")\n",
    "        # print(prices_df.head(3))\n",
    "        \n",
    "    \n",
    "        self.history_df = prices_df\n",
    "        return self.history_df\n",
    "    \n",
    "    \n",
    "#   Assign weights\n",
    "    def assignWeights(self, method=\"Random\"):\n",
    "        \"\"\"Takes a df and assigns weights (defaults to random, but can be either Random or Equal.)\n",
    "        Returns a weights df with columns corresponding to the columns in the df arg.\n",
    "        \"\"\"\n",
    "        # Dict to store weights as values to column name keys\n",
    "        df_weights = {}\n",
    "\n",
    "        # Since the df.columns length will at this point include % change values, weights length should be halved.\n",
    "        weight_array_length = int(len(self.history_df.columns) / 2)\n",
    "        \n",
    "        weights = []\n",
    "        for weight in range(weight_array_length):\n",
    "            weights.append(random.randint(0, 10000))\n",
    "            \n",
    "        new_weights = []\n",
    "        i = 0\n",
    "        for weight in weights:\n",
    "            new_weights.append(round(weights[i] / sum(weights), 2))\n",
    "            i += 1\n",
    "            \n",
    "        # print(\"weights array:\")\n",
    "        # print(str(new_weights))\n",
    "        \n",
    "        # Check whether there are any errors and make the sum = 100\n",
    "        if (sum(new_weights) < 1):\n",
    "            # choose a random index\n",
    "            randIndex = random.randint(0, len(new_weights) - 1)\n",
    "            # print(new_weights[randIndex])\n",
    "            new_weights[randIndex] += (1 - sum(new_weights))\n",
    "            # print(new_weights)\n",
    "        \n",
    "        # Only assign random weights to the columns that don't contain %\n",
    "        if (method == \"Random\"):\n",
    "            # print(\"self.history_df.columns: \"+str(self.history_df.columns))\n",
    "            for item in self.history_df.columns:\n",
    "                # print(\"\\nitem: \"+str(item))\n",
    "                if \"%\" not in item:         \n",
    "                    # print(\"% not in item.\")\n",
    "                    # Add to the dictionary\n",
    "                    # print(\"df_weights[item] now being set to new_weights[self.history_df.get_loc(item)]: \")\n",
    "                    # print(str(new_weights[self.history_df.columns.get_loc(item)]))\n",
    "                    df_weights[str(item)] = new_weights[self.history_df.columns.get_loc(item)]\n",
    "                \n",
    "        elif (method == \"Equal\"):\n",
    "            # Assign equally\n",
    "            df[str(item)+\" Weight\"] = 1 / (len(df.columns) / 2)\n",
    "            \n",
    "        else:\n",
    "            print(\"Choose weighting method: Random or Equal.\")\n",
    "            \n",
    "        self.weights = df_weights\n",
    "        # print(self.weights)\n",
    "        return self.weights\n",
    "        \n",
    "\n",
    "    # Compute portfolio statustics\n",
    "    def get_portfolio_stats(self):\n",
    "        \"\"\"Takes a portfolio price history df and its corresponding weights dict from an assign_weights function,\n",
    "        and returns the weighted HPR and annualized return for the portfolio\"\"\"\n",
    "        \n",
    "        hpr_items = []\n",
    "        stdev_items = []\n",
    "        \n",
    "        # Reset index to make using loc practical\n",
    "        self.history_df = self.history_df.reset_index()\n",
    "        non_date_columns = self.history_df.iloc[:, 1:]\n",
    "        \n",
    "        # Compute total cumulative % change for each asset\n",
    "        for item in non_date_columns.columns:\n",
    "            # print(\"\\nitem: \"+str(item))\n",
    "            if (\"%\" not in item) & (\"/\" not in item):\n",
    "                # print(\"% and / not in item.\")\n",
    "                \n",
    "                beginning_price = non_date_columns.loc[0 , item]\n",
    "                # print(\"Beginning price:\")\n",
    "                # print(beginning_price)\n",
    "                \n",
    "                ending_price = non_date_columns.loc[non_date_columns.index[-1], item]\n",
    "                # print(\"Ending price:\")\n",
    "                # print(ending_price)\n",
    "                \n",
    "                item_hpr = (ending_price - beginning_price) / beginning_price\n",
    "                # print(\"HPR for \"+str(item)+\":\")\n",
    "                # print(item_hpr)\n",
    "                \n",
    "                hpr_items.append(item_hpr)\n",
    "                \n",
    "            elif (\"%\" in item):\n",
    "            # Compute standard deviation of daily % changes for each asset\n",
    "                col_std = non_date_columns[item].std()\n",
    "                stdev_items.append(col_std)\n",
    "                \n",
    "            \n",
    "            # Multiply by weights...\n",
    "            # First for HPR array\n",
    "            weighted_hpr_items = []\n",
    "            i = 0\n",
    "            for item in hpr_items:\n",
    "                weighted_hpr_items.append(hpr_items[i] * self.weights[non_date_columns.columns[i]])\n",
    "                i += 1\n",
    "            # Then for the stdev array\n",
    "            weighted_stdev_items = []\n",
    "            i = 0\n",
    "            for item in stdev_items:\n",
    "                weighted_stdev_items.append(stdev_items[i] * self.weights[non_date_columns.columns[i]])\n",
    "                i += 1\n",
    "                \n",
    "        # print(\"weighted hpr_items: \"+str(weighted_hpr_items))\n",
    "        portfolio_hpr = sum(weighted_hpr_items)\n",
    "        # print(portfolio_hpr)\n",
    "        \n",
    "        # print(\"weighted stdev_items: \"+str(weighted_stdev_items))\n",
    "        portfolio_stdev = sum(weighted_stdev_items)\n",
    "        # print(portfolio_stdev)\n",
    "        \n",
    "        # Adjust by the period analyzed...\n",
    "        \n",
    "        # Compute the percentage of a trading year this period represents\n",
    "        trading_days = 252\n",
    "        df_days = len(non_date_columns.iloc[:, 0])\n",
    "        # print(\"trading days in period analyzed: \"+str(df_days))\n",
    "        pct_of_year = df_days / trading_days\n",
    "        # print(\"% of trading year: \"+str(pct_of_year))\n",
    "        \n",
    "        # Extrapolate for annualized return using appropriate formula\n",
    "        annualized_hpr = (1 + portfolio_hpr) ** (1 / pct_of_year) - 1\n",
    "        # print(\"annualized return: \"+str(annualized_hpr))\n",
    "        \n",
    "        # Apply a similar process to the standard deviation using the sqrt of period analyzed\n",
    "        annualized_volatility = portfolio_stdev * np.sqrt(df_days)\n",
    "        # print(\"annualized volatility: \"+str(annualized_volatility))\n",
    "        \n",
    "        # Now compute annualized risk-adjusted return\n",
    "        risk_adj_return = annualized_hpr / annualized_volatility\n",
    "        # print(\"Risk-Adjusted Return: \"+str(risk_adj_return))\n",
    "\n",
    "        # Convert all of this information on the portfolio to its own dataframe\n",
    "        portfolio_statistics = {\n",
    "            \"num_days\": [df_days],\n",
    "            \"period_start\": [self.history_df.loc[0, \"Date\"]],\n",
    "            \"period_end\": [self.history_df.loc[self.history_df.index[-1], \"Date\"]],\n",
    "            \"num_stocks\": [int(len(non_date_columns.columns) / 2)],\n",
    "            \"hpr\": [portfolio_hpr],\n",
    "            \"annualized_return\": [annualized_hpr],\n",
    "            \"stdev\": [portfolio_stdev],\n",
    "            \"annualized_stdev\": [annualized_volatility],\n",
    "            \"risk_adj_return\": [risk_adj_return]\n",
    "        }\n",
    "        stats_df = pd.DataFrame(portfolio_statistics)\n",
    "        self.analysis_df = stats_df\n",
    "        \n",
    "        # Output\n",
    "        #   Write analysis metrics to analysis_df\n",
    "        return self.analysis_df\n",
    "\n",
    "    #   TODO: Compare analysis to benchmark for alpha\n",
    "    def compare_benchmark(self, benchmark=\"SPY\"):\n",
    "        \"\"\"Defaults to SPY, compares using the same n_periods and start_date params\"\"\"\n",
    "        bench_df = pd.DataFrame({})\n",
    "        bench_performance_df = pd.DataFrame({})\n",
    "        \n",
    "        print(\"Start date index: \"+str(self.start_date_index))\n",
    "        print(\"n_periods: \"+str(self.n_periods))\n",
    "        print(\"Start date: \"+str(reset_df[\"Date\"].iloc[self.start_date_index]))\n",
    "        \n",
    "        # Pull data for SPY\n",
    "        print(\"df.loc[\"+str(self.start_date_index)+\" : \"+str(self.start_date_index+self.n_periods)+\", [\"+str(benchmark)+\"]]: \")\n",
    "        # print(+str(df.loc[self.start_date_index : self.start_date_index + self.n_periods, [benchmark]]))\n",
    "        bench_df[benchmark] = reset_df.loc[self.start_date_index : self.start_date_index + self.n_periods, [benchmark]]\n",
    "        print(\"bench_df.head():\")\n",
    "        print(bench_df.head())\n",
    "        \n",
    "        # Load with the percentage change columns\n",
    "        for item in bench_df.columns:\n",
    "    #       First, load with values\n",
    "            bench_df[str(item)+\" % chg\"] = bench_df[item].pct_change()\n",
    "            \n",
    "        beginning_price = bench_df.loc[self.start_date_index , benchmark]\n",
    "        # print(\"Beginning price:\")\n",
    "        # print(beginning_price)\n",
    "                \n",
    "        ending_price = bench_df.loc[bench_df.index[-1], benchmark]\n",
    "        # print(\"Ending price:\")\n",
    "        # print(ending_price)\n",
    "        \n",
    "        bench_hpr = (ending_price - beginning_price) / beginning_price\n",
    "        # print(\"HPR for \"+str(bench)+\":\")\n",
    "        # print(bench_hpr)\n",
    "        \n",
    "        bench_performance_df[\"hpr\"] = bench_hpr\n",
    "        \n",
    "        # Compute annualized return\n",
    "        trading_days = 252\n",
    "        df_days = len(bench_df.iloc[:, 0])\n",
    "        # print(\"trading days in period analyzed: \"+str(df_days))\n",
    "        pct_of_year = df_days / trading_days\n",
    "        # print(\"% of trading year: \"+str(pct_of_year))\n",
    "        \n",
    "        # Extrapolate for annualized return using appropriate formula\n",
    "        annualized_hpr = (1 + bench_hpr) ** (1 / pct_of_year) - 1\n",
    "        bench_performance_df[\"annualized_return\"] = annualized_hpr\n",
    "        \n",
    "        bench_stdev = bench_df[benchmark].std()\n",
    "        bench_performance_df[\"stdev\"] = bench_stdev\n",
    "        \n",
    "        annualized_volatility = bench_stdev * np.sqrt(df_days)\n",
    "        bench_performance_df[\"annualized_stdev\"] = annualized_volatility\n",
    "        \n",
    "        bench_performance_df[\"risk_adj_return\"] = annualized_hpr / annualized_volatility\n",
    "        \n",
    "        # Compute metrics and return as a df\n",
    "        print(bench_performance_df.head())\n",
    "        \n",
    "    \n",
    "    # Write included tickers and weights to a df\n",
    "    def get_portfolio_comp(self):\n",
    "        # return a df with columns corresponding to tickers and weights\n",
    "        return pd.DataFrame(list(self.weights.items()), columns=[\"Ticker\", \"Weight\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set start date index for portfolio instance to: 5256\n",
      "11/20/2020\n",
      "Initialized new Portfolio instance\n",
      "Start date index: 5256\n",
      "n_periods: 10\n",
      "Start date: 11/20/2020\n",
      "df.loc[5256 : 5266, [SPY]]: \n",
      "bench_df.head():\n",
      "             SPY\n",
      "5256  339.821472\n",
      "5257  341.858490\n",
      "5258  347.367096\n",
      "5259  346.831543\n",
      "5260  347.797516\n",
      "Empty DataFrame\n",
      "Columns: [hpr, annualized_return, stdev, annualized_stdev, risk_adj_return]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can only merge Series or DataFrame objects, a <class 'NoneType'> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Bootcamp\\Python\\EfficientPortfolio\\EfficientPortfolioNotebook.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jonathan/Desktop/Bootcamp/Python/EfficientPortfolio/EfficientPortfolioNotebook.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     stats_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([stats_df, portfolio\u001b[39m.\u001b[39mget_portfolio_stats()])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jonathan/Desktop/Bootcamp/Python/EfficientPortfolio/EfficientPortfolioNotebook.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m# Store the benchmark comparison\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Jonathan/Desktop/Bootcamp/Python/EfficientPortfolio/EfficientPortfolioNotebook.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     bench_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(bench_df, portfolio\u001b[39m.\u001b[39;49mcompare_benchmark(), left_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, right_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, how\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minner\u001b[39;49m\u001b[39m\"\u001b[39;49m) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jonathan/Desktop/Bootcamp/Python/EfficientPortfolio/EfficientPortfolioNotebook.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m composition_df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m comp_df_cols\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jonathan/Desktop/Bootcamp/Python/EfficientPortfolio/EfficientPortfolioNotebook.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m stats_df \u001b[39m=\u001b[39m stats_df\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m--> 110\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    111\u001b[0m         left,\n\u001b[0;32m    112\u001b[0m         right,\n\u001b[0;32m    113\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m    114\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m    115\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[0;32m    116\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[0;32m    117\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[0;32m    118\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[0;32m    119\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    120\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[0;32m    121\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[0;32m    122\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    123\u001b[0m     )\n\u001b[0;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result(copy\u001b[39m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:645\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    630\u001b[0m     left: DataFrame \u001b[39m|\u001b[39m Series,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    642\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    643\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    644\u001b[0m     _left \u001b[39m=\u001b[39m _validate_operand(left)\n\u001b[1;32m--> 645\u001b[0m     _right \u001b[39m=\u001b[39m _validate_operand(right)\n\u001b[0;32m    646\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_left \u001b[39m=\u001b[39m _left\n\u001b[0;32m    647\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_right \u001b[39m=\u001b[39m _right\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:2426\u001b[0m, in \u001b[0;36m_validate_operand\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   2424\u001b[0m         \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   2425\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2426\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   2427\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan only merge Series or DataFrame objects, a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(obj)\u001b[39m}\u001b[39;00m\u001b[39m was passed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2428\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Can only merge Series or DataFrame objects, a <class 'NoneType'> was passed"
     ]
    }
   ],
   "source": [
    "# Testbed\n",
    "stats_df = pd.DataFrame({})\n",
    "composition_df = pd.DataFrame({})\n",
    "bench_df = pd.DataFrame({})\n",
    "comp_df_cols = []\n",
    "for x in range(2):\n",
    "    \n",
    "    portfolio = Portfolio(size=14, n_periods=10, start_date=\"11/20/2020\")\n",
    "    \n",
    "    # Rename columns with a suffix based on the iteration\n",
    "    suffix = \"_\"+str(x)\n",
    "    comp_df_cols.append(\"Ticker\"+suffix)\n",
    "    comp_df_cols.append(\"Weight\"+suffix)\n",
    "\n",
    "    # Merge with outer join to preserve non-identical weights and tickers for each portfolio\n",
    "    composition_df = pd.merge(composition_df, portfolio.get_portfolio_comp(), left_index=True, right_index=True, how=\"outer\")\n",
    "    stats_df = pd.concat([stats_df, portfolio.get_portfolio_stats()])\n",
    "\n",
    "    # Store the benchmark comparison\n",
    "    bench_df = pd.merge(bench_df, portfolio.compare_benchmark(), left_index=True, right_index=True, how=\"inner\") \n",
    "    \n",
    "composition_df.columns = comp_df_cols\n",
    "    \n",
    "stats_df = stats_df.reset_index(drop=True)\n",
    "    \n",
    "stats_df.head(10)\n",
    "# composition_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMFC</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UHT</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOGN</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TAKD</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ERIC</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EKNL</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ALE</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JMM</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LQMT</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SBSI</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MBI</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VHI</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAC</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Weight\n",
       "0    AMFC    0.10\n",
       "1     UHT    0.10\n",
       "2    NVDA    0.06\n",
       "3    LOGN    0.02\n",
       "4    TAKD    0.02\n",
       "5    ERIC    0.05\n",
       "6    EKNL    0.11\n",
       "7     ALE    0.02\n",
       "8     JMM    0.09\n",
       "9    LQMT    0.07\n",
       "10   SBSI    0.11\n",
       "11    MBI    0.09\n",
       "12    VHI    0.12\n",
       "13    CAC    0.04"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composition_df.head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
