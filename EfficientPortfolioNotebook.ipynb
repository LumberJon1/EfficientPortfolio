{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709e3394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAAP</th>\n",
       "      <th>AABB</th>\n",
       "      <th>AAC</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAMC</th>\n",
       "      <th>AAME</th>\n",
       "      <th>AAN</th>\n",
       "      <th>AAOI</th>\n",
       "      <th>...</th>\n",
       "      <th>ZSTN</th>\n",
       "      <th>ZTR</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>ZULU</th>\n",
       "      <th>ZUMZ</th>\n",
       "      <th>ZVLO</th>\n",
       "      <th>ZVTK</th>\n",
       "      <th>ZWBC</th>\n",
       "      <th>ZYNE</th>\n",
       "      <th>ZYXI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01/03/2000</th>\n",
       "      <td>43.76</td>\n",
       "      <td>70.69</td>\n",
       "      <td>24.50</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.87</td>\n",
       "      <td>18.19</td>\n",
       "      <td>9.26</td>\n",
       "      <td>2.09</td>\n",
       "      <td>24.51</td>\n",
       "      <td>9.96</td>\n",
       "      <td>...</td>\n",
       "      <td>7.52</td>\n",
       "      <td>2.46</td>\n",
       "      <td>29.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12.44</td>\n",
       "      <td>26.75</td>\n",
       "      <td>3750000.0</td>\n",
       "      <td>12.75</td>\n",
       "      <td>16.25</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/04/2000</th>\n",
       "      <td>40.42</td>\n",
       "      <td>71.02</td>\n",
       "      <td>25.00</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.96</td>\n",
       "      <td>19.33</td>\n",
       "      <td>8.65</td>\n",
       "      <td>2.15</td>\n",
       "      <td>20.62</td>\n",
       "      <td>10.10</td>\n",
       "      <td>...</td>\n",
       "      <td>7.20</td>\n",
       "      <td>2.48</td>\n",
       "      <td>29.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12.26</td>\n",
       "      <td>25.00</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>12.75</td>\n",
       "      <td>19.32</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/05/2000</th>\n",
       "      <td>37.91</td>\n",
       "      <td>75.11</td>\n",
       "      <td>25.26</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.78</td>\n",
       "      <td>19.05</td>\n",
       "      <td>8.26</td>\n",
       "      <td>2.20</td>\n",
       "      <td>17.75</td>\n",
       "      <td>10.00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2.49</td>\n",
       "      <td>29.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12.05</td>\n",
       "      <td>27.50</td>\n",
       "      <td>7500000.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>24.54</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/06/2000</th>\n",
       "      <td>36.46</td>\n",
       "      <td>74.13</td>\n",
       "      <td>25.02</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.83</td>\n",
       "      <td>19.81</td>\n",
       "      <td>8.39</td>\n",
       "      <td>2.09</td>\n",
       "      <td>17.02</td>\n",
       "      <td>10.00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.55</td>\n",
       "      <td>2.51</td>\n",
       "      <td>29.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12.12</td>\n",
       "      <td>25.50</td>\n",
       "      <td>4450000.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>35.14</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/07/2000</th>\n",
       "      <td>39.50</td>\n",
       "      <td>73.91</td>\n",
       "      <td>24.62</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.90</td>\n",
       "      <td>20.27</td>\n",
       "      <td>8.96</td>\n",
       "      <td>2.15</td>\n",
       "      <td>16.88</td>\n",
       "      <td>9.97</td>\n",
       "      <td>...</td>\n",
       "      <td>7.31</td>\n",
       "      <td>2.56</td>\n",
       "      <td>29.98</td>\n",
       "      <td>0.05</td>\n",
       "      <td>11.75</td>\n",
       "      <td>27.34</td>\n",
       "      <td>2750000.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>29.73</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6076 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                A     AA   AAAP   AABB   AAC    AAL  AAMC  AAME    AAN   AAOI  \\\n",
       "Date                                                                            \n",
       "01/03/2000  43.76  70.69  24.50  77.49  9.87  18.19  9.26  2.09  24.51   9.96   \n",
       "01/04/2000  40.42  71.02  25.00  77.49  9.96  19.33  8.65  2.15  20.62  10.10   \n",
       "01/05/2000  37.91  75.11  25.26  77.49  9.78  19.05  8.26  2.20  17.75  10.00   \n",
       "01/06/2000  36.46  74.13  25.02  77.49  9.83  19.81  8.39  2.09  17.02  10.00   \n",
       "01/07/2000  39.50  73.91  24.62  77.49  9.90  20.27  8.96  2.15  16.88   9.97   \n",
       "\n",
       "            ...  ZSTN   ZTR    ZTS  ZULU   ZUMZ   ZVLO        ZVTK   ZWBC  \\\n",
       "Date        ...                                                             \n",
       "01/03/2000  ...  7.52  2.46  29.05  0.06  12.44  26.75   3750000.0  12.75   \n",
       "01/04/2000  ...  7.20  2.48  29.06  0.06  12.26  25.00  10000000.0  12.75   \n",
       "01/05/2000  ...  7.50  2.49  29.08  0.05  12.05  27.50   7500000.0  30.00   \n",
       "01/06/2000  ...  7.55  2.51  29.07  0.05  12.12  25.50   4450000.0  25.00   \n",
       "01/07/2000  ...  7.31  2.56  29.98  0.05  11.75  27.34   2750000.0  16.00   \n",
       "\n",
       "             ZYNE  ZYXI  \n",
       "Date                     \n",
       "01/03/2000  16.25  1.28  \n",
       "01/04/2000  19.32  1.31  \n",
       "01/05/2000  24.54  1.32  \n",
       "01/06/2000  35.14  1.31  \n",
       "01/07/2000  29.73  1.29  \n",
       "\n",
       "[5 rows x 6076 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"all_history.csv\")\n",
    "df = df.set_index(\"Date\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "reset_df = df.reset_index()\n",
    "date_value = reset_df.loc[reset_df[\"Date\"] == \"01/05/2000\", \"Date\"].index[0]\n",
    "\n",
    "print(date_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 6004 entries, 0 to 6003\n",
      "Series name: Date\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "6004 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "reset_df[\"Date\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb02867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will store the period, start date, and portfolios in a class file.  We can then have\n",
    "# an array of Portfolios to compare.\n",
    "\n",
    "class Portfolio:\n",
    "    # instance variables/attributes...\n",
    "    size = 10 # The initial size or num_stocks in the portfolio\n",
    "    n_periods = 10 # The number of trading days the portfolio analysis takes place over\n",
    "    start_date_index = 0\n",
    "    \n",
    "    weights = pd.DataFrame({}) # Weights that will be assigned to each of the assets in the portfolio\n",
    "    \n",
    "    stdev = 0\n",
    "    hpr = 0\n",
    "    hpr_annualized = 0\n",
    "    risk_adj_return = 0\n",
    "    alpha = 0\n",
    "    \n",
    "    history_df = pd.DataFrame({})\n",
    "    analysis_df = pd.DataFrame({})\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, size, n_periods, start_date=\"Random\"):\n",
    "        \n",
    "        self.size = size\n",
    "        self.n_periods = n_periods\n",
    "        \n",
    "        # If a number is given for start_date, set start_date_index to that number\n",
    "        if (type(start_date) == int):\n",
    "            # print(\"Chose an int index for start_date_index\")\n",
    "            self.start_date_index = start_date\n",
    "        \n",
    "        # TODO: Else if a date is given, find that index\n",
    "        elif (start_date != \"Random\"):\n",
    "            # TODO: Validate format and catch errors or re-format properly\n",
    "            start_date = df.reset_index().loc[reset_df[\"Date\"] == \"01/05/2000\", \"Date\"].index[0]\n",
    "            # print(\"Found index within df at \"+str(start_date))\n",
    "            \n",
    "            self.start_date_index = start_date\n",
    "            \n",
    "        \n",
    "        # Else (or if no args are given) - randomize\n",
    "        else:\n",
    "            self.randomize_start()\n",
    "        \n",
    "        \n",
    "        # Generate history_df\n",
    "        self.create_portfolio()\n",
    "        \n",
    "        # Assign weights\n",
    "        self.assignWeights()\n",
    "        \n",
    "        print(\"Initialized new Portfolio instance\")\n",
    "        \n",
    "    \n",
    "    # Methods...\n",
    "    \n",
    "    # NOTE: Both randomize_ricker and randomize_start need access to the massive CSV file and currently take a pre-made df\n",
    "    # not as an argument, but as a variable inside them.  This will need to be changed in whatever file I move this to.\n",
    "    def randomize_ticker(self):\n",
    "        ticker_index = random.randint(0, len(df.columns) - 1)\n",
    "        sub_df = df.iloc[:, ticker_index]\n",
    "        return sub_df.name.upper()\n",
    "    \n",
    "\n",
    "    def randomize_start(self):\n",
    "        \"\"\"Takes a length parameter that will be added to a random start date and represent the period analyzed\"\"\"\n",
    "        # NOTE: This uses the length of df, which does not exist in the class.  Might be better to define the read_csv here in the class file.\n",
    "        # Perhaps pass it as an argument in randomize_start and have that param point to the read_csv\n",
    "        rand_start = random.randint(0, (len(df) - self.n_periods))\n",
    "        \n",
    "        self.start_date_index = rand_start\n",
    "        return self.start_date_index\n",
    "    \n",
    "    \n",
    "    def create_portfolio(self):\n",
    "    #   df to hold the data from each ticker\n",
    "        prices_df = pd.DataFrame({})\n",
    "\n",
    "        start_index = self.start_date_index\n",
    "        \n",
    "        i = 0\n",
    "        while i < self.size:\n",
    "    #       Run the randomizer and trim values\n",
    "            ticker = self.randomize_ticker()\n",
    "            ticker_index = df.columns.get_loc(ticker)\n",
    "            ticker_df = df.iloc[start_index : start_index + self.n_periods, [ticker_index]]\n",
    "\n",
    "    #       Clean null values and randomize again if necessary\n",
    "            ticker_df = ticker_df.dropna()\n",
    "            if (len(ticker_df) < self.n_periods):\n",
    "                # Break and decrement i if there are null values in the date range\n",
    "                # print(\"\\nSeries contains null values.  Choosing a different ticker...\")\n",
    "                i -= 1\n",
    "\n",
    "            else:\n",
    "                # Add the data as intended.\n",
    "                if prices_df.empty:\n",
    "                    prices_df = ticker_df\n",
    "                else:\n",
    "                    prices_df = pd.concat([prices_df, ticker_df], axis=1)\n",
    "    #                   prices_df = prices_df.merge(prices_df, ticker_df)\n",
    "    #       \n",
    "            i += 1\n",
    "        \n",
    "        # Load with the percentage change columns\n",
    "        for item in prices_df.columns:\n",
    "    #       First, load with values\n",
    "            prices_df[str(item)+\" % chg\"] = prices_df[item].pct_change()\n",
    "        \n",
    "        # print(\"\\n\\nFinal prices_df: \")\n",
    "        # print(prices_df.head(3))\n",
    "        \n",
    "    \n",
    "        self.history_df = prices_df\n",
    "        return self.history_df\n",
    "    \n",
    "    \n",
    "#   Assign weights\n",
    "    def assignWeights(self, method=\"Random\"):\n",
    "        \"\"\"Takes a df and assigns weights (defaults to random, but can be either Random or Equal.)\n",
    "        Returns a weights df with columns corresponding to the columns in the df arg.\n",
    "        \"\"\"\n",
    "        # Dict to store weights as values to column name keys\n",
    "        df_weights = {}\n",
    "\n",
    "        # Since the df.columns length will at this point include % change values, weights length should be halved.\n",
    "        weight_array_length = int(len(self.history_df.columns) / 2)\n",
    "        \n",
    "        weights = []\n",
    "        for weight in range(weight_array_length):\n",
    "            weights.append(random.randint(0, 10000))\n",
    "            \n",
    "        new_weights = []\n",
    "        i = 0\n",
    "        for weight in weights:\n",
    "            new_weights.append(round(weights[i] / sum(weights), 2))\n",
    "            i += 1\n",
    "            \n",
    "        # print(\"weights array:\")\n",
    "        # print(str(new_weights))\n",
    "        \n",
    "        # Check whether there are any errors and make the sum = 100\n",
    "        if (sum(new_weights) < 1):\n",
    "            # choose a random index\n",
    "            randIndex = random.randint(0, len(new_weights) - 1)\n",
    "            # print(new_weights[randIndex])\n",
    "            new_weights[randIndex] += (1 - sum(new_weights))\n",
    "            # print(new_weights)\n",
    "        \n",
    "        # Only assign random weights to the columns that don't contain %\n",
    "        if (method == \"Random\"):\n",
    "            # print(\"self.history_df.columns: \"+str(self.history_df.columns))\n",
    "            for item in self.history_df.columns:\n",
    "                # print(\"\\nitem: \"+str(item))\n",
    "                if \"%\" not in item:         \n",
    "                    # print(\"% not in item.\")\n",
    "                    # Add to the dictionary\n",
    "                    # print(\"df_weights[item] now being set to new_weights[self.history_df.get_loc(item)]: \")\n",
    "                    # print(str(new_weights[self.history_df.columns.get_loc(item)]))\n",
    "                    df_weights[str(item)] = new_weights[self.history_df.columns.get_loc(item)]\n",
    "                \n",
    "        elif (method == \"Equal\"):\n",
    "            # Assign equally\n",
    "            df[str(item)+\" Weight\"] = 1 / (len(df.columns) / 2)\n",
    "            \n",
    "        else:\n",
    "            print(\"Choose weighting method: Random or Equal.\")\n",
    "            \n",
    "        self.weights = df_weights\n",
    "        # print(self.weights)\n",
    "        return self.weights\n",
    "        \n",
    "\n",
    "    # Compute portfolio statustics\n",
    "    def get_portfolio_stats(self):\n",
    "        \"\"\"Takes a portfolio price history df and its corresponding weights dict from an assign_weights function,\n",
    "        and returns the weighted HPR and annualized return for the portfolio\"\"\"\n",
    "        \n",
    "        hpr_items = []\n",
    "        stdev_items = []\n",
    "        \n",
    "        # Reset index to make using loc practical\n",
    "        self.history_df = self.history_df.reset_index()\n",
    "        non_date_columns = self.history_df.iloc[:, 1:]\n",
    "        \n",
    "        # Compute total cumulative % change for each asset\n",
    "        for item in non_date_columns.columns:\n",
    "            # print(\"\\nitem: \"+str(item))\n",
    "            if (\"%\" not in item) & (\"/\" not in item):\n",
    "                # print(\"% and / not in item.\")\n",
    "                \n",
    "                beginning_price = non_date_columns.loc[0 , item]\n",
    "                # print(\"Beginning price:\")\n",
    "                # print(beginning_price)\n",
    "                \n",
    "                ending_price = non_date_columns.loc[non_date_columns.index[-1], item]\n",
    "                # print(\"Ending price:\")\n",
    "                # print(ending_price)\n",
    "                \n",
    "                item_hpr = (ending_price - beginning_price) / beginning_price\n",
    "                # print(\"HPR for \"+str(item)+\":\")\n",
    "                # print(item_hpr)\n",
    "                \n",
    "                hpr_items.append(item_hpr)\n",
    "                \n",
    "            elif (\"%\" in item):\n",
    "            # Compute standard deviation of daily % changes for each asset\n",
    "                col_std = non_date_columns[item].std()\n",
    "                stdev_items.append(col_std)\n",
    "                \n",
    "            \n",
    "            # Multiply by weights...\n",
    "            # First for HPR array\n",
    "            weighted_hpr_items = []\n",
    "            i = 0\n",
    "            for item in hpr_items:\n",
    "                weighted_hpr_items.append(hpr_items[i] * self.weights[non_date_columns.columns[i]])\n",
    "                i += 1\n",
    "            # Then for the stdev array\n",
    "            weighted_stdev_items = []\n",
    "            i = 0\n",
    "            for item in stdev_items:\n",
    "                weighted_stdev_items.append(stdev_items[i] * self.weights[non_date_columns.columns[i]])\n",
    "                i += 1\n",
    "                \n",
    "        # print(\"weighted hpr_items: \"+str(weighted_hpr_items))\n",
    "        portfolio_hpr = sum(weighted_hpr_items)\n",
    "        # print(portfolio_hpr)\n",
    "        \n",
    "        # print(\"weighted stdev_items: \"+str(weighted_stdev_items))\n",
    "        portfolio_stdev = sum(weighted_stdev_items)\n",
    "        # print(portfolio_stdev)\n",
    "        \n",
    "        # Adjust by the period analyzed...\n",
    "        \n",
    "        # Compute the percentage of a trading year this period represents\n",
    "        trading_days = 252\n",
    "        df_days = len(non_date_columns.iloc[:, 0])\n",
    "        # print(\"trading days in period analyzed: \"+str(df_days))\n",
    "        pct_of_year = df_days / trading_days\n",
    "        # print(\"% of trading year: \"+str(pct_of_year))\n",
    "        \n",
    "        # Extrapolate for annualized return using appropriate formula\n",
    "        annualized_hpr = (1 + portfolio_hpr) ** (1 / pct_of_year) - 1\n",
    "        # print(\"annualized return: \"+str(annualized_hpr))\n",
    "        \n",
    "        # Apply a similar process to the standard deviation using the sqrt of period analyzed\n",
    "        annualized_volatility = portfolio_stdev * np.sqrt(df_days)\n",
    "        # print(\"annualized volatility: \"+str(annualized_volatility))\n",
    "        \n",
    "        # Now compute annualized risk-adjusted return\n",
    "        risk_adj_return = annualized_hpr / annualized_volatility\n",
    "        # print(\"Risk-Adjusted Return: \"+str(risk_adj_return))\n",
    "\n",
    "        # Convert all of this information on the portfolio to its own dataframe\n",
    "        portfolio_statistics = {\n",
    "            \"num_days\": [df_days],\n",
    "            \"period_start\": [self.history_df.loc[0, \"Date\"]],\n",
    "            \"period_end\": [self.history_df.loc[self.history_df.index[-1], \"Date\"]],\n",
    "            \"num_stocks\": [int(len(non_date_columns.columns) / 2)],\n",
    "            \"hpr\": [portfolio_hpr],\n",
    "            \"annualized_return\": [annualized_hpr],\n",
    "            \"stdev\": [portfolio_stdev],\n",
    "            \"annualized_stdev\": [annualized_volatility],\n",
    "            \"risk_adj_return\": [risk_adj_return]\n",
    "        }\n",
    "        stats_df = pd.DataFrame(portfolio_statistics)\n",
    "        self.analysis_df = stats_df\n",
    "        \n",
    "        # Output\n",
    "        #   Write analysis metrics to analysis_df\n",
    "        return self.analysis_df\n",
    "\n",
    "    #   TODO: Compare analysis to benchmark for alpha\n",
    "    def compare_benchmark(self, benchmark=\"SPY\"):\n",
    "        \"\"\"Defaults to SPY, compares using the same n_periods and start_date params\"\"\"\n",
    "        bench_df = pd.DataFrame({})\n",
    "        bench_performance_df = pd.DataFrame({})\n",
    "        \n",
    "        # Pull data for SPY\n",
    "        bench_df[benchmark] = df.loc[self.start_date_index : self.start_date_index + self.n_periods, [benchmark]]\n",
    "        \n",
    "        # Load with the percentage change columns\n",
    "        for item in bench_df.columns:\n",
    "    #       First, load with values\n",
    "            bench_df[str(item)+\" % chg\"] = bench_df[item].pct_change()\n",
    "            \n",
    "        beginning_price = bench_df.loc[0 , benchmark]\n",
    "        # print(\"Beginning price:\")\n",
    "        # print(beginning_price)\n",
    "                \n",
    "        ending_price = bench_df.loc[df.index[-1], benchmark]\n",
    "        # print(\"Ending price:\")\n",
    "        # print(ending_price)\n",
    "        \n",
    "        bench_hpr = (ending_price - beginning_price) / beginning_price\n",
    "        # print(\"HPR for \"+str(bench)+\":\")\n",
    "        # print(bench_hpr)\n",
    "        \n",
    "        bench_performance_df[\"hpr\"] = bench_hpr\n",
    "        \n",
    "        # Compute annualized return\n",
    "        trading_days = 252\n",
    "        df_days = len(bench_df.iloc[:, 0])\n",
    "        # print(\"trading days in period analyzed: \"+str(df_days))\n",
    "        pct_of_year = df_days / trading_days\n",
    "        # print(\"% of trading year: \"+str(pct_of_year))\n",
    "        \n",
    "        # Extrapolate for annualized return using appropriate formula\n",
    "        annualized_hpr = (1 + bench_hpr) ** (1 / pct_of_year) - 1\n",
    "        bench_performance_df[\"annualized_return\"] = annualized_hpr\n",
    "        \n",
    "        bench_stdev = bench_df[benchmark].std()\n",
    "        bench_performance_df[\"stdev\"] = bench_stdev\n",
    "        \n",
    "        annualized_volatility = bench_stdev * np.sqrt(df_days)\n",
    "        bench_performance_df[\"annualized_stdev\"] = annualized_volatility\n",
    "        \n",
    "        bench_performance_df[\"risk_adj_return\"] = annualized_hpr / annualized_volatility\n",
    "        \n",
    "        # Compute metrics and return as a df\n",
    "        print(bench_performance_df.head())\n",
    "        \n",
    "    \n",
    "    # Write included tickers and weights to a df\n",
    "    def get_portfolio_comp(self):\n",
    "        # return a df with columns corresponding to tickers and weights\n",
    "        return pd.DataFrame(list(self.weights.items()), columns=[\"Ticker\", \"Weight\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized new Portfolio instance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonathan\\AppData\\Local\\Temp\\ipykernel_18876\\2849658317.py:200: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  item_hpr = (ending_price - beginning_price) / beginning_price\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot do slice indexing on Index with these indexers [2] of type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Bootcamp\\Python\\EfficientPortfolio\\EfficientPortfolioNotebook.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jonathan/Desktop/Bootcamp/Python/EfficientPortfolio/EfficientPortfolioNotebook.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     stats_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([stats_df, portfolio\u001b[39m.\u001b[39mget_portfolio_stats()])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jonathan/Desktop/Bootcamp/Python/EfficientPortfolio/EfficientPortfolioNotebook.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m# Store the benchmark comparison\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Jonathan/Desktop/Bootcamp/Python/EfficientPortfolio/EfficientPortfolioNotebook.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     bench_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(bench_df, portfolio\u001b[39m.\u001b[39;49mcompare_benchmark(), left_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, right_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minner\u001b[39m\u001b[39m\"\u001b[39m) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jonathan/Desktop/Bootcamp/Python/EfficientPortfolio/EfficientPortfolioNotebook.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m composition_df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m comp_df_cols\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jonathan/Desktop/Bootcamp/Python/EfficientPortfolio/EfficientPortfolioNotebook.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m stats_df \u001b[39m=\u001b[39m stats_df\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\Jonathan\\Desktop\\Bootcamp\\Python\\EfficientPortfolio\\EfficientPortfolioNotebook.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jonathan/Desktop/Bootcamp/Python/EfficientPortfolio/EfficientPortfolioNotebook.ipynb#W3sZmlsZQ%3D%3D?line=277'>278</a>\u001b[0m     bench_performance_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({})\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jonathan/Desktop/Bootcamp/Python/EfficientPortfolio/EfficientPortfolioNotebook.ipynb#W3sZmlsZQ%3D%3D?line=279'>280</a>\u001b[0m     \u001b[39m# Pull data for SPY\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Jonathan/Desktop/Bootcamp/Python/EfficientPortfolio/EfficientPortfolioNotebook.ipynb#W3sZmlsZQ%3D%3D?line=280'>281</a>\u001b[0m     bench_df[benchmark] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mloc[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart_date_index : \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart_date_index \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_periods, [benchmark]]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jonathan/Desktop/Bootcamp/Python/EfficientPortfolio/EfficientPortfolioNotebook.ipynb#W3sZmlsZQ%3D%3D?line=282'>283</a>\u001b[0m     \u001b[39m# Load with the percentage change columns\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jonathan/Desktop/Bootcamp/Python/EfficientPortfolio/EfficientPortfolioNotebook.ipynb#W3sZmlsZQ%3D%3D?line=283'>284</a>\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m bench_df\u001b[39m.\u001b[39mcolumns:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jonathan/Desktop/Bootcamp/Python/EfficientPortfolio/EfficientPortfolioNotebook.ipynb#W3sZmlsZQ%3D%3D?line=284'>285</a>\u001b[0m \u001b[39m#       First, load with values\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1256\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1256\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:924\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[0;32m    922\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 924\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m    925\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1290\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[0;32m   1289\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1290\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_slice_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1291\u001b[0m \u001b[39melif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m   1292\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getbool_axis(key, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1324\u001b[0m, in \u001b[0;36m_LocIndexer._get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1323\u001b[0m labels \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m-> 1324\u001b[0m indexer \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39;49mslice_indexer(slice_obj\u001b[39m.\u001b[39;49mstart, slice_obj\u001b[39m.\u001b[39;49mstop, slice_obj\u001b[39m.\u001b[39;49mstep)\n\u001b[0;32m   1326\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(indexer, \u001b[39mslice\u001b[39m):\n\u001b[0;32m   1327\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_slice(indexer, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6559\u001b[0m, in \u001b[0;36mIndex.slice_indexer\u001b[1;34m(self, start, end, step, kind)\u001b[0m\n\u001b[0;32m   6516\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6517\u001b[0m \u001b[39mCompute the slice indexer for input labels and step.\u001b[39;00m\n\u001b[0;32m   6518\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6555\u001b[0m \u001b[39mslice(1, 3, None)\u001b[39;00m\n\u001b[0;32m   6556\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6557\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deprecated_arg(kind, \u001b[39m\"\u001b[39m\u001b[39mkind\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mslice_indexer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 6559\u001b[0m start_slice, end_slice \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mslice_locs(start, end, step\u001b[39m=\u001b[39;49mstep)\n\u001b[0;32m   6561\u001b[0m \u001b[39m# return a slice\u001b[39;00m\n\u001b[0;32m   6562\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(start_slice):\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6767\u001b[0m, in \u001b[0;36mIndex.slice_locs\u001b[1;34m(self, start, end, step, kind)\u001b[0m\n\u001b[0;32m   6765\u001b[0m start_slice \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   6766\u001b[0m \u001b[39mif\u001b[39;00m start \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 6767\u001b[0m     start_slice \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_slice_bound(start, \u001b[39m\"\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   6768\u001b[0m \u001b[39mif\u001b[39;00m start_slice \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   6769\u001b[0m     start_slice \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6676\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[1;34m(self, label, side, kind)\u001b[0m\n\u001b[0;32m   6672\u001b[0m original_label \u001b[39m=\u001b[39m label\n\u001b[0;32m   6674\u001b[0m \u001b[39m# For datetime indices label may be a string that has to be converted\u001b[39;00m\n\u001b[0;32m   6675\u001b[0m \u001b[39m# to datetime boundary according to its resolution.\u001b[39;00m\n\u001b[1;32m-> 6676\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_cast_slice_bound(label, side)\n\u001b[0;32m   6678\u001b[0m \u001b[39m# we need to look up the label\u001b[39;00m\n\u001b[0;32m   6679\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jonathan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6623\u001b[0m, in \u001b[0;36mIndex._maybe_cast_slice_bound\u001b[1;34m(self, label, side, kind)\u001b[0m\n\u001b[0;32m   6618\u001b[0m \u001b[39m# We are a plain index here (sub-class override this method if they\u001b[39;00m\n\u001b[0;32m   6619\u001b[0m \u001b[39m# wish to have special treatment for floats/ints, e.g. Float64Index and\u001b[39;00m\n\u001b[0;32m   6620\u001b[0m \u001b[39m# datetimelike Indexes\u001b[39;00m\n\u001b[0;32m   6621\u001b[0m \u001b[39m# reject them, if index does not contain label\u001b[39;00m\n\u001b[0;32m   6622\u001b[0m \u001b[39mif\u001b[39;00m (is_float(label) \u001b[39mor\u001b[39;00m is_integer(label)) \u001b[39mand\u001b[39;00m label \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m-> 6623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalid_indexer(\u001b[39m\"\u001b[39m\u001b[39mslice\u001b[39m\u001b[39m\"\u001b[39m, label)\n\u001b[0;32m   6625\u001b[0m \u001b[39mreturn\u001b[39;00m label\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot do slice indexing on Index with these indexers [2] of type int64"
     ]
    }
   ],
   "source": [
    "# Testbed\n",
    "stats_df = pd.DataFrame({})\n",
    "composition_df = pd.DataFrame({})\n",
    "bench_df = pd.DataFrame({})\n",
    "comp_df_cols = []\n",
    "for x in range(2):\n",
    "    \n",
    "    portfolio = Portfolio(size=14, n_periods=10, start_date=\"11/21/2020\")\n",
    "    \n",
    "    # Rename columns with a suffix based on the iteration\n",
    "    suffix = \"_\"+str(x)\n",
    "    comp_df_cols.append(\"Ticker\"+suffix)\n",
    "    comp_df_cols.append(\"Weight\"+suffix)\n",
    "\n",
    "    # Merge with outer join to preserve non-identical weights and tickers for each portfolio\n",
    "    composition_df = pd.merge(composition_df, portfolio.get_portfolio_comp(), left_index=True, right_index=True, how=\"outer\")\n",
    "    stats_df = pd.concat([stats_df, portfolio.get_portfolio_stats()])\n",
    "\n",
    "    # Store the benchmark comparison\n",
    "    bench_df = pd.merge(bench_df, portfolio.compare_benchmark(), left_index=True, right_index=True, how=\"inner\") \n",
    "    \n",
    "composition_df.columns = comp_df_cols\n",
    "    \n",
    "stats_df = stats_df.reset_index(drop=True)\n",
    "    \n",
    "stats_df.head(10)\n",
    "# composition_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker_0</th>\n",
       "      <th>Weight_0</th>\n",
       "      <th>Ticker_1</th>\n",
       "      <th>Weight_1</th>\n",
       "      <th>Ticker_2</th>\n",
       "      <th>Weight_2</th>\n",
       "      <th>Ticker_3</th>\n",
       "      <th>Weight_3</th>\n",
       "      <th>Ticker_4</th>\n",
       "      <th>Weight_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticker_15</th>\n",
       "      <th>Weight_15</th>\n",
       "      <th>Ticker_16</th>\n",
       "      <th>Weight_16</th>\n",
       "      <th>Ticker_17</th>\n",
       "      <th>Weight_17</th>\n",
       "      <th>Ticker_18</th>\n",
       "      <th>Weight_18</th>\n",
       "      <th>Ticker_19</th>\n",
       "      <th>Weight_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMTL</td>\n",
       "      <td>0.46</td>\n",
       "      <td>SEAC</td>\n",
       "      <td>0.15</td>\n",
       "      <td>EBIX</td>\n",
       "      <td>0.35</td>\n",
       "      <td>LOAN</td>\n",
       "      <td>0.27</td>\n",
       "      <td>MKC-V</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>BIDU</td>\n",
       "      <td>0.08</td>\n",
       "      <td>TALN</td>\n",
       "      <td>0.31</td>\n",
       "      <td>NEE</td>\n",
       "      <td>0.23</td>\n",
       "      <td>PII</td>\n",
       "      <td>0.10</td>\n",
       "      <td>JMTM</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FISI</td>\n",
       "      <td>0.51</td>\n",
       "      <td>COKE</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NORD</td>\n",
       "      <td>0.04</td>\n",
       "      <td>IQI</td>\n",
       "      <td>0.22</td>\n",
       "      <td>NSYS</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>CSL</td>\n",
       "      <td>0.71</td>\n",
       "      <td>GBX</td>\n",
       "      <td>0.31</td>\n",
       "      <td>SDON</td>\n",
       "      <td>0.14</td>\n",
       "      <td>SENEA</td>\n",
       "      <td>0.34</td>\n",
       "      <td>CCM</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GVSI</td>\n",
       "      <td>0.03</td>\n",
       "      <td>MCRAA</td>\n",
       "      <td>0.10</td>\n",
       "      <td>MOV</td>\n",
       "      <td>0.39</td>\n",
       "      <td>EZTD</td>\n",
       "      <td>0.26</td>\n",
       "      <td>HARL</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>NBTB</td>\n",
       "      <td>0.13</td>\n",
       "      <td>TTI</td>\n",
       "      <td>0.12</td>\n",
       "      <td>AQMS</td>\n",
       "      <td>0.39</td>\n",
       "      <td>PXLW</td>\n",
       "      <td>0.24</td>\n",
       "      <td>CHYL</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SDON</td>\n",
       "      <td>0.01</td>\n",
       "      <td>VHC</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NATI</td>\n",
       "      <td>0.22</td>\n",
       "      <td>SEDN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>ASBN</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>KIM</td>\n",
       "      <td>0.08</td>\n",
       "      <td>DGIX</td>\n",
       "      <td>0.26</td>\n",
       "      <td>COBZ</td>\n",
       "      <td>0.24</td>\n",
       "      <td>MCR</td>\n",
       "      <td>0.32</td>\n",
       "      <td>ENBN</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker_0  Weight_0 Ticker_1  Weight_1 Ticker_2  Weight_2 Ticker_3  Weight_3  \\\n",
       "0     IMTL      0.46     SEAC      0.15     EBIX      0.35     LOAN      0.27   \n",
       "1     FISI      0.51     COKE      0.65     NORD      0.04      IQI      0.22   \n",
       "2     GVSI      0.03    MCRAA      0.10      MOV      0.39     EZTD      0.26   \n",
       "3     SDON      0.01      VHC      0.10     NATI      0.22     SEDN      0.25   \n",
       "\n",
       "  Ticker_4  Weight_4  ... Ticker_15  Weight_15 Ticker_16  Weight_16 Ticker_17  \\\n",
       "0    MKC-V      0.19  ...      BIDU       0.08      TALN       0.31       NEE   \n",
       "1     NSYS      0.07  ...       CSL       0.71       GBX       0.31      SDON   \n",
       "2     HARL      0.27  ...      NBTB       0.13       TTI       0.12      AQMS   \n",
       "3     ASBN      0.47  ...       KIM       0.08      DGIX       0.26      COBZ   \n",
       "\n",
       "   Weight_17 Ticker_18  Weight_18 Ticker_19  Weight_19  \n",
       "0       0.23       PII       0.10      JMTM       0.26  \n",
       "1       0.14     SENEA       0.34       CCM       0.15  \n",
       "2       0.39      PXLW       0.24      CHYL       0.44  \n",
       "3       0.24       MCR       0.32      ENBN       0.15  \n",
       "\n",
       "[4 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composition_df.head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
