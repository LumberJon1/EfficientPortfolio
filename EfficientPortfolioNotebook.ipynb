{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "709e3394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAAP</th>\n",
       "      <th>AABB</th>\n",
       "      <th>AAC</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAMC</th>\n",
       "      <th>AAME</th>\n",
       "      <th>AAN</th>\n",
       "      <th>AAOI</th>\n",
       "      <th>...</th>\n",
       "      <th>ZSTN</th>\n",
       "      <th>ZTR</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>ZULU</th>\n",
       "      <th>ZUMZ</th>\n",
       "      <th>ZVLO</th>\n",
       "      <th>ZVTK</th>\n",
       "      <th>ZWBC</th>\n",
       "      <th>ZYNE</th>\n",
       "      <th>ZYXI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01/03/2000</th>\n",
       "      <td>43.76</td>\n",
       "      <td>70.69</td>\n",
       "      <td>24.50</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.87</td>\n",
       "      <td>18.19</td>\n",
       "      <td>9.26</td>\n",
       "      <td>2.09</td>\n",
       "      <td>24.51</td>\n",
       "      <td>9.96</td>\n",
       "      <td>...</td>\n",
       "      <td>7.52</td>\n",
       "      <td>2.46</td>\n",
       "      <td>29.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12.44</td>\n",
       "      <td>26.75</td>\n",
       "      <td>3750000.0</td>\n",
       "      <td>12.75</td>\n",
       "      <td>16.25</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/04/2000</th>\n",
       "      <td>40.42</td>\n",
       "      <td>71.02</td>\n",
       "      <td>25.00</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.96</td>\n",
       "      <td>19.33</td>\n",
       "      <td>8.65</td>\n",
       "      <td>2.15</td>\n",
       "      <td>20.62</td>\n",
       "      <td>10.10</td>\n",
       "      <td>...</td>\n",
       "      <td>7.20</td>\n",
       "      <td>2.48</td>\n",
       "      <td>29.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12.26</td>\n",
       "      <td>25.00</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>12.75</td>\n",
       "      <td>19.32</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/05/2000</th>\n",
       "      <td>37.91</td>\n",
       "      <td>75.11</td>\n",
       "      <td>25.26</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.78</td>\n",
       "      <td>19.05</td>\n",
       "      <td>8.26</td>\n",
       "      <td>2.20</td>\n",
       "      <td>17.75</td>\n",
       "      <td>10.00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2.49</td>\n",
       "      <td>29.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12.05</td>\n",
       "      <td>27.50</td>\n",
       "      <td>7500000.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>24.54</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/06/2000</th>\n",
       "      <td>36.46</td>\n",
       "      <td>74.13</td>\n",
       "      <td>25.02</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.83</td>\n",
       "      <td>19.81</td>\n",
       "      <td>8.39</td>\n",
       "      <td>2.09</td>\n",
       "      <td>17.02</td>\n",
       "      <td>10.00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.55</td>\n",
       "      <td>2.51</td>\n",
       "      <td>29.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12.12</td>\n",
       "      <td>25.50</td>\n",
       "      <td>4450000.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>35.14</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/07/2000</th>\n",
       "      <td>39.50</td>\n",
       "      <td>73.91</td>\n",
       "      <td>24.62</td>\n",
       "      <td>77.49</td>\n",
       "      <td>9.90</td>\n",
       "      <td>20.27</td>\n",
       "      <td>8.96</td>\n",
       "      <td>2.15</td>\n",
       "      <td>16.88</td>\n",
       "      <td>9.97</td>\n",
       "      <td>...</td>\n",
       "      <td>7.31</td>\n",
       "      <td>2.56</td>\n",
       "      <td>29.98</td>\n",
       "      <td>0.05</td>\n",
       "      <td>11.75</td>\n",
       "      <td>27.34</td>\n",
       "      <td>2750000.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>29.73</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6076 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                A     AA   AAAP   AABB   AAC    AAL  AAMC  AAME    AAN   AAOI  \\\n",
       "Date                                                                            \n",
       "01/03/2000  43.76  70.69  24.50  77.49  9.87  18.19  9.26  2.09  24.51   9.96   \n",
       "01/04/2000  40.42  71.02  25.00  77.49  9.96  19.33  8.65  2.15  20.62  10.10   \n",
       "01/05/2000  37.91  75.11  25.26  77.49  9.78  19.05  8.26  2.20  17.75  10.00   \n",
       "01/06/2000  36.46  74.13  25.02  77.49  9.83  19.81  8.39  2.09  17.02  10.00   \n",
       "01/07/2000  39.50  73.91  24.62  77.49  9.90  20.27  8.96  2.15  16.88   9.97   \n",
       "\n",
       "            ...  ZSTN   ZTR    ZTS  ZULU   ZUMZ   ZVLO        ZVTK   ZWBC  \\\n",
       "Date        ...                                                             \n",
       "01/03/2000  ...  7.52  2.46  29.05  0.06  12.44  26.75   3750000.0  12.75   \n",
       "01/04/2000  ...  7.20  2.48  29.06  0.06  12.26  25.00  10000000.0  12.75   \n",
       "01/05/2000  ...  7.50  2.49  29.08  0.05  12.05  27.50   7500000.0  30.00   \n",
       "01/06/2000  ...  7.55  2.51  29.07  0.05  12.12  25.50   4450000.0  25.00   \n",
       "01/07/2000  ...  7.31  2.56  29.98  0.05  11.75  27.34   2750000.0  16.00   \n",
       "\n",
       "             ZYNE  ZYXI  \n",
       "Date                     \n",
       "01/03/2000  16.25  1.28  \n",
       "01/04/2000  19.32  1.31  \n",
       "01/05/2000  24.54  1.32  \n",
       "01/06/2000  35.14  1.31  \n",
       "01/07/2000  29.73  1.29  \n",
       "\n",
       "[5 rows x 6076 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"all_history.csv\")\n",
    "df = df.set_index(\"Date\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "3eb45134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "01/03/2000    70.69\n",
      "01/04/2000    71.02\n",
      "01/05/2000    75.11\n",
      "01/06/2000    74.13\n",
      "01/07/2000    73.91\n",
      "01/10/2000    73.69\n",
      "01/11/2000    73.26\n",
      "01/12/2000    72.60\n",
      "01/13/2000    71.29\n",
      "01/14/2000    69.87\n",
      "Name: AA, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def get_history(begin_date, end_date, stock_index):\n",
    "    # Gets the rows between begin_date and end_date for the stock at df[stock_index]\n",
    "    sub_df = df.iloc[begin_date:end_date, stock_index]\n",
    "    \n",
    "    print(sub_df)\n",
    "    return sub_df\n",
    "        \n",
    "\n",
    "ticker_df = get_history(0, 10, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "5cd69e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_ticker():\n",
    "    ticker_index = random.randint(0, len(df.columns))\n",
    "    sub_df = df.iloc[:, ticker_index]\n",
    "    return sub_df.name.upper()\n",
    "    \n",
    "\n",
    "def randomize_start(period_length):\n",
    "    \"\"\"Takes a length parameter that will be added to a random start date and represent the period analyzed\"\"\"\n",
    "    rand_start = random.randint(0, (len(df) - period_length))\n",
    "    \n",
    "    return rand_start\n",
    "    \n",
    "\n",
    "#   Trim null-valued prices from the df\n",
    "#     prices = df[ticker.upper()]\n",
    "#     prices = prices.dropna()\n",
    "    \n",
    "#   Trim possible dates so that rand_start + period_length will not throw an out-of-bounds exception\n",
    "    \n",
    "    \n",
    "    \n",
    "def create_portfolio(period_length, num_tickers):\n",
    "#   df to hold the data from each ticker\n",
    "    prices_df = pd.DataFrame({})\n",
    "\n",
    "    start_index = randomize_start(period_length)\n",
    "    \n",
    "    i = 0\n",
    "    while i < num_tickers:\n",
    "#       Run the randomizer and trim values\n",
    "        ticker = randomize_ticker()\n",
    "        ticker_index = df.columns.get_loc(ticker)\n",
    "        ticker_df = df.iloc[start_index : start_index + period_length, [ticker_index]]\n",
    "\n",
    "#       Clean null values and randomize again if necessary\n",
    "        ticker_df = ticker_df.dropna()\n",
    "        if (len(ticker_df) < period_length):\n",
    "            # Break and decrement i if there are null values in the date range\n",
    "            print(\"\\nSeries contains null values.  Choosing a different ticker...\")\n",
    "            i -= 1\n",
    "\n",
    "        else:\n",
    "            # Add the data as intended.\n",
    "            if prices_df.empty:\n",
    "                prices_df = ticker_df\n",
    "            else:\n",
    "                prices_df = pd.concat([prices_df, ticker_df], axis=1)\n",
    "#                   prices_df = prices_df.merge(prices_df, ticker_df)\n",
    "#       \n",
    "        i += 1\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\nFinal prices_df: \")\n",
    "    print(prices_df.head(10))\n",
    "    \n",
    "    return prices_df\n",
    "    \n",
    "    \n",
    "# test_ticker = randomize_ticker()\n",
    "# print(test_ticker)\n",
    "\n",
    "# randomize_start(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign random weights\n",
    "def assignWeights(df, method=\"Random\"):\n",
    "    \"\"\"Takes a df and assigns weights (defaults to random, but can be either Random or Equal.)\n",
    "    Returns a weights df with columns corresponding to the columns in the df arg.\n",
    "    \"\"\"\n",
    "    # Dict to store weights as values to column name keys\n",
    "    df_weights = {}\n",
    "\n",
    "    # Since the df.columns length will at this point include % change values, weights length should be halved.\n",
    "    weight_array_length = int(len(df.columns) / 2)\n",
    "    \n",
    "    weights = []\n",
    "    for weight in range(weight_array_length):\n",
    "        weights.append(random.randint(0, 10000))\n",
    "        \n",
    "    new_weights = []\n",
    "    i = 0\n",
    "    for weight in weights:\n",
    "        new_weights.append(round(weights[i] / sum(weights), 2))\n",
    "        i += 1\n",
    "        \n",
    "    print(\"sum:\")\n",
    "    print(sum(new_weights))\n",
    "    \n",
    "    # Check whether there are any errors and make the sum = 100\n",
    "    if (sum(new_weights) < 1):\n",
    "        # choose a random index\n",
    "        randIndex = random.randint(0, len(new_weights))\n",
    "        print(new_weights[randIndex])\n",
    "        new_weights[randIndex] += (1 - sum(new_weights))\n",
    "        print(new_weights)\n",
    "    \n",
    "    # Only assign random weights to the columns that don't contain %\n",
    "    if (method == \"Random\"):\n",
    "        for item in df.columns:\n",
    "            if \"%\" not in item:         \n",
    "                # Add to the dictionary\n",
    "                df_weights[str(item)] = new_weights[df.columns.get_loc(item)]\n",
    "            \n",
    "    elif (method == \"Equal\"):\n",
    "        # Assign equally\n",
    "        df[str(item)+\" Weight\"] = 1 / (len(df.columns) / 2)\n",
    "        \n",
    "    else:\n",
    "        print(\"Choose weighting method: Random or Equal.\")\n",
    "    \n",
    "    print(df_weights)\n",
    "    return df_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Final prices_df: \n",
      "            LMFA  UFMG  FRTG\n",
      "Date                        \n",
      "07/28/2006  0.84  7.11  0.81\n",
      "07/31/2006  0.86  7.11  0.81\n",
      "08/01/2006  0.85  7.11  0.81\n",
      "08/02/2006  0.85  7.11  0.81\n",
      "08/03/2006  0.92  7.11  0.81\n",
      "08/04/2006  0.92  7.11  0.81\n",
      "sum:\n",
      "0.99\n",
      "0.35\n",
      "[0.36, 0.5, 0.14]\n",
      "{'LMFA': 0.36, 'UFMG': 0.5, 'FRTG': 0.14}\n",
      "[0.034285714285714315, 0.0, 0.0]\n",
      "0.034285714285714315\n",
      "[0.013585829598730424, 0.0, 0.0]\n",
      "0.013585829598730424\n",
      "trading days in period analyzed: 6\n",
      "% of trading year: 0.023809523809523808\n",
      "annualized return: 3.1200463297249863\n",
      "annualized volatility: 0.03327835024929027\n",
      "Risk-Adjusted Return: 93.75603977818966\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_days</th>\n",
       "      <th>period_start</th>\n",
       "      <th>period_end</th>\n",
       "      <th>num_stocks</th>\n",
       "      <th>hpr</th>\n",
       "      <th>annualized_return</th>\n",
       "      <th>stdev</th>\n",
       "      <th>annualized_stdev</th>\n",
       "      <th>risk_adj_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>07/28/2006</td>\n",
       "      <td>08/04/2006</td>\n",
       "      <td>3</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>3.120046</td>\n",
       "      <td>0.013586</td>\n",
       "      <td>0.033278</td>\n",
       "      <td>93.75604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_days period_start  period_end  num_stocks       hpr  annualized_return  \\\n",
       "0         6   07/28/2006  08/04/2006           3  0.034286           3.120046   \n",
       "\n",
       "      stdev  annualized_stdev  risk_adj_return  \n",
       "0  0.013586          0.033278         93.75604  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_portfolio_1 = create_portfolio(6, 3)\n",
    "sample_portfolio_1.head()\n",
    "\n",
    "for item in sample_portfolio_1.columns:\n",
    "#     First, load with values\n",
    "    sample_portfolio_1[str(item)+\" % chg\"] = sample_portfolio_1[item].pct_change()\n",
    "\n",
    "\n",
    "def get_portfolio_stats(portfolio_df, portfolio_weights):\n",
    "    \"\"\"Takes a portfolio price history df and its corresponding weights dict from an assign_weights function,\n",
    "    and returns the weighted HPR and annualized return for the portfolio\"\"\"\n",
    "    \n",
    "    hpr_items = []\n",
    "    stdev_items = []\n",
    "    \n",
    "    # Reset index to make using loc practical\n",
    "    portfolio_df = portfolio_df.reset_index()\n",
    "    non_date_columns = portfolio_df.iloc[:, 1:]\n",
    "    \n",
    "    # Compute total cumulative % change for each asset\n",
    "    for item in non_date_columns.columns:\n",
    "        if (\"%\" not in item) & (\"/\" not in item):\n",
    "            \n",
    "            beginning_price = non_date_columns.loc[0 , item]\n",
    "            # print(\"Beginning price:\")\n",
    "            # print(beginning_price)\n",
    "            \n",
    "            ending_price = non_date_columns.loc[non_date_columns.index[-1], item]\n",
    "            # print(\"Ending price:\")\n",
    "            # print(ending_price)\n",
    "            \n",
    "            item_hpr = (ending_price - beginning_price) / beginning_price\n",
    "            # print(\"HPR for \"+str(item)+\":\")\n",
    "            # print(item_hpr)\n",
    "            \n",
    "            hpr_items.append(item_hpr)\n",
    "            \n",
    "        elif (\"%\" in item):\n",
    "        # Compute standard deviation of daily % changes for each asset\n",
    "            col_std = non_date_columns[item].std()\n",
    "            stdev_items.append(col_std)\n",
    "            \n",
    "        \n",
    "        # Multiply by weights...\n",
    "        # First for HPR array\n",
    "        weighted_hpr_items = []\n",
    "        i = 0\n",
    "        for item in hpr_items:\n",
    "            weighted_hpr_items.append(hpr_items[i] * portfolio_weights[non_date_columns.columns[i]])\n",
    "            i += 1\n",
    "        # Then for the stdev array\n",
    "        weighted_stdev_items = []\n",
    "        i = 0\n",
    "        for item in stdev_items:\n",
    "            weighted_stdev_items.append(stdev_items[i] * portfolio_weights[non_date_columns.columns[i]])\n",
    "            i += 1\n",
    "            \n",
    "    print(weighted_hpr_items)\n",
    "    portfolio_hpr = sum(weighted_hpr_items)\n",
    "    print(portfolio_hpr)\n",
    "    \n",
    "    print(weighted_stdev_items)\n",
    "    portfolio_stdev = sum(weighted_stdev_items)\n",
    "    print(portfolio_stdev)\n",
    "    \n",
    "    # Adjust by the period analyzed...\n",
    "    \n",
    "    # Compute the percentage of a trading year this period represents\n",
    "    trading_days = 252\n",
    "    df_days = len(non_date_columns.iloc[:, 0])\n",
    "    print(\"trading days in period analyzed: \"+str(df_days))\n",
    "    pct_of_year = df_days / trading_days\n",
    "    print(\"% of trading year: \"+str(pct_of_year))\n",
    "    \n",
    "    # Extrapolate for annualized return using appropriate formula\n",
    "    annualized_hpr = (1 + portfolio_hpr) ** (1 / pct_of_year) - 1\n",
    "    print(\"annualized return: \"+str(annualized_hpr))\n",
    "    \n",
    "    # Apply a similar process to the standard deviation using the sqrt of period analyzed\n",
    "    annualized_volatility = portfolio_stdev * np.sqrt(df_days)\n",
    "    print(\"annualized volatility: \"+str(annualized_volatility))\n",
    "    \n",
    "    # Now compute annualized risk-adjusted return\n",
    "    risk_adj_return = annualized_hpr / annualized_volatility\n",
    "    print(\"Risk-Adjusted Return: \"+str(risk_adj_return))\n",
    "\n",
    "    # Convert all of this information on the portfolio to its own dataframe\n",
    "    portfolio_statistics = {\n",
    "        \"num_days\": [df_days],\n",
    "        \"period_start\": [portfolio_df.loc[0, \"Date\"]],\n",
    "        \"period_end\": [portfolio_df.loc[portfolio_df.index[-1], \"Date\"]],\n",
    "        \"num_stocks\": [int(len(non_date_columns.columns) / 2)],\n",
    "        \"hpr\": [portfolio_hpr],\n",
    "        \"annualized_return\": [annualized_hpr],\n",
    "        \"stdev\": [portfolio_stdev],\n",
    "        \"annualized_stdev\": [annualized_volatility],\n",
    "        \"risk_adj_return\": [risk_adj_return]\n",
    "    }\n",
    "    portfolio_statistics_df = pd.DataFrame(portfolio_statistics)\n",
    "    \n",
    "    # Output\n",
    "    return portfolio_statistics_df\n",
    "    \n",
    "    \n",
    "# Testbed\n",
    "get_portfolio_stats(sample_portfolio_1, assignWeights(sample_portfolio_1, \"Random\")).head()\n",
    "# sample_portfolio_1.head(50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fb02867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            PHOS  HOFT    WTS    IMO  PHOS % chg  HOFT % chg  WTS % chg  \\\n",
      "Date                                                                      \n",
      "06/01/2009   0.0  7.70  18.29  33.72         NaN         NaN        NaN   \n",
      "06/02/2009   0.0  7.39  18.09  33.65         NaN   -0.040260  -0.010935   \n",
      "06/03/2009   0.0  7.21  18.33  32.05         NaN   -0.024357   0.013267   \n",
      "\n",
      "            IMO % chg  \n",
      "Date                   \n",
      "06/01/2009        NaN  \n",
      "06/02/2009  -0.002076  \n",
      "06/03/2009  -0.047548  \n",
      "weights array:\n",
      "[0.46, 0.0, 0.33, 0.21]\n",
      "self.history_df.columns: Index(['PHOS', 'HOFT', 'WTS', 'IMO', 'PHOS % chg', 'HOFT % chg', 'WTS % chg',\n",
      "       'IMO % chg'],\n",
      "      dtype='object')\n",
      "\n",
      "item: PHOS\n",
      "% not in item.\n",
      "df_weights[item] now being set to new_weights[self.history_df.get_loc(item)]: \n",
      "0.46\n",
      "\n",
      "item: HOFT\n",
      "% not in item.\n",
      "df_weights[item] now being set to new_weights[self.history_df.get_loc(item)]: \n",
      "0.0\n",
      "\n",
      "item: WTS\n",
      "% not in item.\n",
      "df_weights[item] now being set to new_weights[self.history_df.get_loc(item)]: \n",
      "0.33\n",
      "\n",
      "item: IMO\n",
      "% not in item.\n",
      "df_weights[item] now being set to new_weights[self.history_df.get_loc(item)]: \n",
      "0.21\n",
      "\n",
      "item: PHOS % chg\n",
      "\n",
      "item: HOFT % chg\n",
      "\n",
      "item: WTS % chg\n",
      "\n",
      "item: IMO % chg\n",
      "{'PHOS': 0.46, 'HOFT': 0.0, 'WTS': 0.33, 'IMO': 0.21}\n",
      "Initialized new Portfolio instance\n",
      "\n",
      "item: PHOS\n",
      "% and / not in item.\n",
      "\n",
      "item: HOFT\n",
      "% and / not in item.\n",
      "\n",
      "item: WTS\n",
      "% and / not in item.\n",
      "\n",
      "item: IMO\n",
      "% and / not in item.\n",
      "\n",
      "item: PHOS % chg\n",
      "\n",
      "item: HOFT % chg\n",
      "\n",
      "item: WTS % chg\n",
      "\n",
      "item: IMO % chg\n",
      "[nan, -0.0, 0.009743028977583364, -0.005854092526690378]\n",
      "nan\n",
      "[nan, 0.0, 0.003722312827814686, 0.004833395304563909]\n",
      "nan\n",
      "trading days in period analyzed: 8\n",
      "% of trading year: 0.031746031746031744\n",
      "annualized return: nan\n",
      "annualized volatility: nan\n",
      "Risk-Adjusted Return: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonathan\\AppData\\Local\\Temp\\ipykernel_8580\\2259050428.py:185: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  item_hpr = (ending_price - beginning_price) / beginning_price\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_days</th>\n",
       "      <th>period_start</th>\n",
       "      <th>period_end</th>\n",
       "      <th>num_stocks</th>\n",
       "      <th>hpr</th>\n",
       "      <th>annualized_return</th>\n",
       "      <th>stdev</th>\n",
       "      <th>annualized_stdev</th>\n",
       "      <th>risk_adj_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>06/01/2009</td>\n",
       "      <td>06/10/2009</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_days period_start  period_end  num_stocks  hpr  annualized_return  \\\n",
       "0         8   06/01/2009  06/10/2009           4  NaN                NaN   \n",
       "\n",
       "   stdev  annualized_stdev  risk_adj_return  \n",
       "0    NaN               NaN              NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will store the period, start date, and portfolios in a class file.  We can then have\n",
    "# an array of Portfolios to compare.\n",
    "\n",
    "class Portfolio:\n",
    "    # instance variables/attributes...\n",
    "    size = 10 # The initial size or num_stocks in the portfolio\n",
    "    n_periods = 10 # The number of trading days the portfolio analysis takes place over\n",
    "    start_date_index = 0\n",
    "    \n",
    "    weights = pd.DataFrame({}) # Weights that will be assigned to each of the assets in the portfolio\n",
    "    \n",
    "    stdev = 0\n",
    "    hpr = 0\n",
    "    hpr_annualized = 0\n",
    "    risk_adj_return = 0\n",
    "    alpha = 0\n",
    "    \n",
    "    history_df = pd.DataFrame({})\n",
    "    analysis_df = pd.DataFrame({})\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, size, n_periods):\n",
    "        \n",
    "        self.size = size\n",
    "        self.n_periods = n_periods\n",
    "        \n",
    "        # Randomize starting period within csv\n",
    "        self.randomize_start()\n",
    "        \n",
    "        # Generate history_df\n",
    "        self.create_portfolio()\n",
    "        \n",
    "        # Assign weights\n",
    "        self.assignWeights()\n",
    "        \n",
    "        print(\"Initialized new Portfolio instance\")\n",
    "        \n",
    "    \n",
    "    # Methods...\n",
    "    \n",
    "    # NOTE: Both randomize_ricker and randomize_start need access to the massive CSV file and currently take a pre-made df\n",
    "    # not as an argument, but as a variable inside them.  This will need to be changed in whatever file I move this to.\n",
    "    def randomize_ticker(self):\n",
    "        ticker_index = random.randint(0, len(df.columns))\n",
    "        sub_df = df.iloc[:, ticker_index]\n",
    "        return sub_df.name.upper()\n",
    "    \n",
    "\n",
    "    def randomize_start(self):\n",
    "        \"\"\"Takes a length parameter that will be added to a random start date and represent the period analyzed\"\"\"\n",
    "        period_length = self.n_periods\n",
    "        # NOTE: This uses the length of df, which does not exist in the class.  Might be better to define the read_csv here in the class file.\n",
    "        # Perhaps pass it as an argument in randomize_start and have that param point to the read_csv\n",
    "        rand_start = random.randint(0, (len(df) - period_length))\n",
    "        \n",
    "        self.start_date_index = rand_start\n",
    "        return self.start_date_index\n",
    "    \n",
    "    \n",
    "    def create_portfolio(self):\n",
    "    #   df to hold the data from each ticker\n",
    "        prices_df = pd.DataFrame({})\n",
    "\n",
    "        start_index = self.start_date_index\n",
    "        \n",
    "        i = 0\n",
    "        while i < self.size:\n",
    "    #       Run the randomizer and trim values\n",
    "            ticker = self.randomize_ticker()\n",
    "            ticker_index = df.columns.get_loc(ticker)\n",
    "            ticker_df = df.iloc[start_index : start_index + self.n_periods, [ticker_index]]\n",
    "\n",
    "    #       Clean null values and randomize again if necessary\n",
    "            ticker_df = ticker_df.dropna()\n",
    "            if (len(ticker_df) < self.n_periods):\n",
    "                # Break and decrement i if there are null values in the date range\n",
    "                # print(\"\\nSeries contains null values.  Choosing a different ticker...\")\n",
    "                i -= 1\n",
    "\n",
    "            else:\n",
    "                # Add the data as intended.\n",
    "                if prices_df.empty:\n",
    "                    prices_df = ticker_df\n",
    "                else:\n",
    "                    prices_df = pd.concat([prices_df, ticker_df], axis=1)\n",
    "    #                   prices_df = prices_df.merge(prices_df, ticker_df)\n",
    "    #       \n",
    "            i += 1\n",
    "        \n",
    "        # Load with the percentage change columns\n",
    "        for item in prices_df.columns:\n",
    "    #       First, load with values\n",
    "            prices_df[str(item)+\" % chg\"] = prices_df[item].pct_change()\n",
    "        \n",
    "        # print(\"\\n\\nFinal prices_df: \")\n",
    "        print(prices_df.head(3))\n",
    "        \n",
    "    \n",
    "        self.history_df = prices_df\n",
    "        return self.history_df\n",
    "    \n",
    "    \n",
    "#   Assign weights\n",
    "    def assignWeights(self, method=\"Random\"):\n",
    "        \"\"\"Takes a df and assigns weights (defaults to random, but can be either Random or Equal.)\n",
    "        Returns a weights df with columns corresponding to the columns in the df arg.\n",
    "        \"\"\"\n",
    "        # Dict to store weights as values to column name keys\n",
    "        df_weights = {}\n",
    "\n",
    "        # Since the df.columns length will at this point include % change values, weights length should be halved.\n",
    "        weight_array_length = int(len(self.history_df.columns) / 2)\n",
    "        \n",
    "        weights = []\n",
    "        for weight in range(weight_array_length):\n",
    "            weights.append(random.randint(0, 10000))\n",
    "            \n",
    "        new_weights = []\n",
    "        i = 0\n",
    "        for weight in weights:\n",
    "            new_weights.append(round(weights[i] / sum(weights), 2))\n",
    "            i += 1\n",
    "            \n",
    "        print(\"weights array:\")\n",
    "        print(str(new_weights))\n",
    "        \n",
    "        # Check whether there are any errors and make the sum = 100\n",
    "        if (sum(new_weights) < 1):\n",
    "            # choose a random index\n",
    "            randIndex = random.randint(0, len(new_weights))\n",
    "            print(new_weights[randIndex])\n",
    "            new_weights[randIndex] += (1 - sum(new_weights))\n",
    "            print(new_weights)\n",
    "        \n",
    "        # Only assign random weights to the columns that don't contain %\n",
    "        if (method == \"Random\"):\n",
    "            print(\"self.history_df.columns: \"+str(self.history_df.columns))\n",
    "            for item in self.history_df.columns:\n",
    "                print(\"\\nitem: \"+str(item))\n",
    "                if \"%\" not in item:         \n",
    "                    print(\"% not in item.\")\n",
    "                    # Add to the dictionary\n",
    "                    print(\"df_weights[item] now being set to new_weights[self.history_df.get_loc(item)]: \")\n",
    "                    print(str(new_weights[self.history_df.columns.get_loc(item)]))\n",
    "                    df_weights[str(item)] = new_weights[self.history_df.columns.get_loc(item)]\n",
    "                \n",
    "        elif (method == \"Equal\"):\n",
    "            # Assign equally\n",
    "            df[str(item)+\" Weight\"] = 1 / (len(df.columns) / 2)\n",
    "            \n",
    "        else:\n",
    "            print(\"Choose weighting method: Random or Equal.\")\n",
    "            \n",
    "        self.weights = df_weights\n",
    "        print(self.weights)\n",
    "        return self.weights\n",
    "        \n",
    "\n",
    "    # Compute portfolio statustics\n",
    "    def get_portfolio_stats(self):\n",
    "        \"\"\"Takes a portfolio price history df and its corresponding weights dict from an assign_weights function,\n",
    "        and returns the weighted HPR and annualized return for the portfolio\"\"\"\n",
    "        \n",
    "        hpr_items = []\n",
    "        stdev_items = []\n",
    "        \n",
    "        # Reset index to make using loc practical\n",
    "        self.history_df = self.history_df.reset_index()\n",
    "        non_date_columns = self.history_df.iloc[:, 1:]\n",
    "        \n",
    "        # Compute total cumulative % change for each asset\n",
    "        for item in non_date_columns.columns:\n",
    "            print(\"\\nitem: \"+str(item))\n",
    "            if (\"%\" not in item) & (\"/\" not in item):\n",
    "                print(\"% and / not in item.\")\n",
    "                \n",
    "                beginning_price = non_date_columns.loc[0 , item]\n",
    "                # print(\"Beginning price:\")\n",
    "                # print(beginning_price)\n",
    "                \n",
    "                ending_price = non_date_columns.loc[non_date_columns.index[-1], item]\n",
    "                # print(\"Ending price:\")\n",
    "                # print(ending_price)\n",
    "                \n",
    "                item_hpr = (ending_price - beginning_price) / beginning_price\n",
    "                # print(\"HPR for \"+str(item)+\":\")\n",
    "                # print(item_hpr)\n",
    "                \n",
    "                hpr_items.append(item_hpr)\n",
    "                \n",
    "            elif (\"%\" in item):\n",
    "            # Compute standard deviation of daily % changes for each asset\n",
    "                col_std = non_date_columns[item].std()\n",
    "                stdev_items.append(col_std)\n",
    "                \n",
    "            \n",
    "            # Multiply by weights...\n",
    "            # First for HPR array\n",
    "            weighted_hpr_items = []\n",
    "            i = 0\n",
    "            for item in hpr_items:\n",
    "                weighted_hpr_items.append(hpr_items[i] * self.weights[non_date_columns.columns[i]])\n",
    "                i += 1\n",
    "            # Then for the stdev array\n",
    "            weighted_stdev_items = []\n",
    "            i = 0\n",
    "            for item in stdev_items:\n",
    "                weighted_stdev_items.append(stdev_items[i] * self.weights[non_date_columns.columns[i]])\n",
    "                i += 1\n",
    "                \n",
    "        print(weighted_hpr_items)\n",
    "        portfolio_hpr = sum(weighted_hpr_items)\n",
    "        print(portfolio_hpr)\n",
    "        \n",
    "        print(weighted_stdev_items)\n",
    "        portfolio_stdev = sum(weighted_stdev_items)\n",
    "        print(portfolio_stdev)\n",
    "        \n",
    "        # Adjust by the period analyzed...\n",
    "        \n",
    "        # Compute the percentage of a trading year this period represents\n",
    "        trading_days = 252\n",
    "        df_days = len(non_date_columns.iloc[:, 0])\n",
    "        print(\"trading days in period analyzed: \"+str(df_days))\n",
    "        pct_of_year = df_days / trading_days\n",
    "        print(\"% of trading year: \"+str(pct_of_year))\n",
    "        \n",
    "        # Extrapolate for annualized return using appropriate formula\n",
    "        annualized_hpr = (1 + portfolio_hpr) ** (1 / pct_of_year) - 1\n",
    "        print(\"annualized return: \"+str(annualized_hpr))\n",
    "        \n",
    "        # Apply a similar process to the standard deviation using the sqrt of period analyzed\n",
    "        annualized_volatility = portfolio_stdev * np.sqrt(df_days)\n",
    "        print(\"annualized volatility: \"+str(annualized_volatility))\n",
    "        \n",
    "        # Now compute annualized risk-adjusted return\n",
    "        risk_adj_return = annualized_hpr / annualized_volatility\n",
    "        print(\"Risk-Adjusted Return: \"+str(risk_adj_return))\n",
    "\n",
    "        # Convert all of this information on the portfolio to its own dataframe\n",
    "        portfolio_statistics = {\n",
    "            \"num_days\": [df_days],\n",
    "            \"period_start\": [self.history_df.loc[0, \"Date\"]],\n",
    "            \"period_end\": [self.history_df.loc[self.history_df.index[-1], \"Date\"]],\n",
    "            \"num_stocks\": [int(len(non_date_columns.columns) / 2)],\n",
    "            \"hpr\": [portfolio_hpr],\n",
    "            \"annualized_return\": [annualized_hpr],\n",
    "            \"stdev\": [portfolio_stdev],\n",
    "            \"annualized_stdev\": [annualized_volatility],\n",
    "            \"risk_adj_return\": [risk_adj_return]\n",
    "        }\n",
    "        stats_df = pd.DataFrame(portfolio_statistics)\n",
    "        self.analysis_df = stats_df\n",
    "        \n",
    "        # Output\n",
    "        #   Write analysis metrics to analysis_df\n",
    "        return self.analysis_df\n",
    "\n",
    "    #   Compare analysis to benchmark for alpha\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Testbed\n",
    "portfolio_1 = Portfolio(4, 8)\n",
    "portfolio_1.get_portfolio_stats()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
